整体思路：总分总

1. 一句话概括要回答的问题
2. 展开说明，一定要有层次和连接词（首先，其次，然后，最后       1.2.3.4）
3. 最后一句话总结下答案，回扣一下答案（总之）

~~~markdown
- 不要说不会（这是态度问题，可以说我回去再研究一下） 
- 不要背答案（问题背过之后，一定要转化为自己的语言） 
- 不要追完美（把自己能表达清楚的说好就可以，不需要100%跟答案一致） 
- 不要胡乱说（可能一句话就是暴露了自己的水平）
~~~



# 基础(*)

## JDK和JRE的区别

JDK是Java开发工具包，JRE是Java运行时环境，二者的区别在于

- JRE是Java程序运行所必须的，它包含jvm和一些Java的基础类库

- JDK是Java程序开发所必须的，它包含JRE和一些开发工具


总结一下就是：JDK包含JRE，如果仅仅是运行Java程序，只要有JRE即可；如果是要开发Java程序，则必须要有JDK

## Java的基础数据类型有哪些（重点）

Java中一共有8种基本类型，分别是：

- 整数类型：byte、short、int、long，它们分别占1、2、4、8个字节
- 浮点数类型：float、double，分别占4、8个字节
- 字符类型：char，占2个字节
- 布尔类型：boolean，占1个字节 

## Java面向对象的三大特性（重点）

**封装** : 就是把客观事物封装成抽象的类，将事物的特征功能抽取为类的属性和方法 , 供其他被允许的类调用 ,  屏蔽了内部具体的实现细节 , 保证安全

**继承** : 就是子类继承父类 , 可以继承父类中所定义的属性和方法。通过使用继承我们能够非常方便地复用以前的代码

**多态：**父类或接口定义的引用变量可以指向子类或具体实现类的实例对象。多态可以降低代码之间的耦合

## 什么是多态机制

所谓多态就是父类或接口定义的引用变量可以指向子类或具体实现类的实例对象。例如 : `List list = new ArrayList() `

Java实现多态有三个必要条件：继承、重写、向上转型

- 继承：在多态中必须存在有继承关系的子类和父类
- 重写：子类对父类中某些方法进行重新定义，在调用这些方法时就会调用子类的方法
- 向上转型：在多态中需要父类的引用指向子类对象，只有这样该引用才能够既调用父类的方法也能调用子类的方法

## 创建对象的方式有哪些

1. 使用new关键字调用构造方法直接创建对象
2. 使用反射创建对象：获取类的字节码对象 , 调用`newInstance()`方法创建
3. 如果一个类实现了Cloneable接口 , 还可以使用`clone()`方法克隆对象

## final和finally的区别

final和finally都是Java提供的关键字

- final是一个修饰符，可以修饰类、变量、方法

  修饰类表示该类不能被继承；修饰方法表示该方法不能被重写；修饰变量表示该变量是一个常量不能被重新赋值 

- finally用于Java中的异常处理，要和try、catch配合使用

  写在finally代码块中的程序，无论程序是否出现异常，都会被执行，一般用来释放一些资源

## String、StringBuffer、 StringBuilder的区别（重点）

这几个都是关于字符串的类，他们的区别点有下面几个

1. 可变性：String是不可变字符串，StringBuffer和 StringBuilder是可变字符串
2. 线程安全性：String和StringBuffer是线程安全的，StringBuilder是线程不安全的
3. 效率：StringBuilder效率最高，StringBuffer居中，String效率最低
4. 使用场景：少量字符串的操作使用String，大量字符串的频繁操作在多线程下使用StringBuffer，单线程下可以使用StringBuilder

## 使用=和new创建字符串的区别

两种方式都可以创建出字符串，但是在内存分配上却是不一样的

* =方式：JVM会在常量池中创建一个字符串对象

* new方式：JVM会先判断常量池中是否有此字符串，如果没有，它就会在常量池中创建一个，然后再从堆内存中重新创建一个


## 重写和重载的区别

重载和重写都是用于描述方法间的关系的，但是他们的含义和场景确大不相同

- 重写是存在于子父类之间的，一般用在父类的方法无法满足子类需求时，子类重写方法来自定义方法功能

  它要求子类定义的方法与父类中的方法具有相同的方法名字和参数列表

- 重载是存在于同一个类中的，一般用在功能相似的方法需要接收不同的参数时

  它要求多个方法具有相同的名字，但要有不同的参数列表

## ==与equals的区别（重点）

1. ==是一个运算符，equals是Object类的方法
2. 用于基本类型的变量比较时：==比较的是值是否相等，equals不能直接用于基本数据类型的比较，需要转换为其对应的包装类型
3. 用于引用类型的比较时。==和equals都是比较栈内存中的地址是否相等，但是通常会重写equals方法去实现对象内容的比较

## 接口和抽象类的区别

接口和抽象类在我们开发过程中使用的都很多，它们的共同点是：都不能用于创建对象

它们的不同点是：

  1. 抽象类一般用于抽取子类中的共同方法和属性，接口一般用于指定实现类的规范
  2. 抽象类可以有构造方法，用于给抽象父类中的属性进行赋值；而接口中不能有构造方法
  3. 抽象类可以有静态代码块，接口不能有静态代码块
  4. 一个类只能继承一个抽象类，而一个类却可以实现多个接口

## 说出几个常见的异常（重点）

Java中的异常分为运行时异常和编译时异常两大类：

- 运行时异常都是RuntimeException类及其子类，这类异常的特点是不强行要求程序员进行处理，常见的有

  NullPointerException 空指针异常，调用了未经初始化的对象或者是不存在的对象

  IndexOutOfBoundsException 索引越界异常，常见于操作了不存在的索引时发生

  ClassCastException 数据类型转换异常

- 非运行时异常，也叫编译异常，是Exception的子类但不是RuntimeException的子类，类型上都属于及其子类

  它要求程序员在编写代码的过程中提供异常处理方案，否则编译不通过，常见的有：IOException和SQLException等

## Stream流中的常用方法有哪些

```Java
void forEach(Consumer<? super T> action); //用于遍历Stream中的元素
<R> Stream<R> map(Function<? super T, ? extends R> mapper); //用于对流中的元素进行转换操作
Stream<T> filter(Predicate<? super T> predicate); //用于对Stream中的元素进行过滤，只保留满足条件的元素
Stream<T> distinct(); //用于去除Stream中重复的元素
Stream<T> limit(long maxSize); //用于限制Stream中元素的数量，截取前n个元素
Stream<T> skip(long n); //用于跳过Stream中前n个元素
Stream<T> sorted(Comparator<? super T> comparator); //用于对Stream中的元素进行排序
<R, A> R collect(Collector<? super T, A, R> collector); //用于将Stream中的元素收集起来，转换成其他数据结构，如List、Set等
```

## Java中常见的集合类有哪些（重点）

我们常见的集合主要有两大类，分别是单列集合和双列集合

1. 单列集合的顶级接口是Collection，它下面有两个主要的子接口分别是List和Set

   List的特点是元素有序的，可以重复的；Set的特点是元素无序的，不可重复的

   List下我们常用的类有ArrayList、LinkedList等，Set下我们常用的类有HashSet、LinkedHashSet等

2. 双列集合的顶级接口是Map，它的特点是每个元素都有键和值两部分组成，而且键不能重复

   Map接口下我们常用的类有：HashMap、LinkedHashMap等

## ArrayList和LinkedList的区别（重点）

ArrayList和LinkedList都是Java中的单列结合，都是有序的，可重复的

不同点有下面几个：

1. 底层数据结构不同：ArrayList底层是动态数组，而LinkedList底层是双向链表 
2. 使用场景不同：ArrayList查询快，增删慢，适合查询场景；LinkedList查询慢，增删快，适合频繁修改的场景
3. 占用内存空间不同：LinkedList比ArrayList更占内存，这是因为它的每个节点除了存储数据，还存储了前后节点的引用两个引用

## HashMap的底层原理（重点）

HashMap底层数据结构是哈希表，哈希表在JDK1.8之前是数组+链表实现，在JDK1.8之后是数组+链表+红黑树实现的 

下面我以map中存储对象的流程给您说一下它的实现原理把

1. 当我们创建一个HashMap的时候，JDK就会在内存中创建一个长度为16的数组

2. 当我们调用put方法像HashMap中保存一个元素的时候，它会先调用key的hashCode方法计算出key的hash值

   然后使用得到hash值对数组长度取余，找出当前对象的元素在数组中的位置 

3. 接下来，它会判断算出的位置上是否有元素，如果没有，就会将此元素直接存储到当前位置上

   如果算出的位置上有元素或者是有链表，它会再调用key的equals方法跟存在元素的key做比较

   如果有一个比较得到的结果为true，则会进行值的覆盖，如果都为false，则会将元素追加在链表的末尾

当然，为了降低Hash冲突和链表长度，HashMap还做了一些优化

1. 当元素的数量超过数组大小与加载因子的乘积的时候，就会执行扩容，扩容为原来的2倍，并将原来数组中的键重新进行hash运算，然后分配到新数组中

2. 当链表的长度>8，并且数组长度>=64的时候，链表就会转换为红黑树，当红黑树结点数小于6时将再次转回为链表

## HashMap如何解决哈希冲突

​		首先，HashMap的底层有一个数组，它在保存元素的时候，会对元素的key进行hash运算，得到hash值，然后再使用hash值对数组长度取余，得到元素在数组中的位置，这样的话，不同的元素计算完毕之后，就可能会被分配到数组中的同一个位置上，这就是所谓的哈希冲突

​		解决hash冲突最常用的方式有链表法和开放地址法，而HashMap就是采用了链表法。具体做法就是当哈希冲突出现之后，HashMap会在发生冲突的位置上创建一个链表来保存元素，当然在JDK1.8之后，又对此做出了改进，那就是当链表的长度>8，并且数组长度>=64的时候，链表就会转换为红黑树，使得效率更高

## HashMap和HashTable区别

HashMap和HashTable都是Map的子类，都可以存储键值对的数据，区别点在于HashTable是线程安全，HashMap则不是

HashTable的线程安全是通过底层在每个方法上添加synchronized实现的，因此它的效率要比HashMap低

HashTable在我们公司中已经不再使用，我对它的了解也不是特别多，我们公司一般都是采用的HashMap

如果碰到需要线程安全的场景，我们则会使用ConcurrentHashMap，而不用HashTable，所以我对它的了解也就这些

## ConcurrentHashMap的实现原理（重点）

在JDK1.7的时候ConcurrentHashMap的底层数据结构是Segment数组 + HashEntry的形式实现

ConcurrentHashMap首先会将数据分为一段一段的存储 , 每个分段就是一个Segment，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问 , 在默认情况下 , 会将底层数据划分为16个分段  , 所以性能相对于HashTable而言提高了16倍

Segment数组中的每一个Segment元素保存的是一个HashEntry数组 , 这个HashEntry数组的结构就跟HashMap比较类似, 使用的是数组 + 链表结构

![img](assets/download_image-1733899964081.png) 

在JDK1.8的时候，放弃了Segment臃肿的设计，底层的数据结构和HashMap的数据结构相同

采用Node + CAS + Synchronized来保证并发安全进行实现，synchronized只锁定当前链表或红黑树的首节点，这样只要hash不冲突，就不会产生并发 , 效率得到提升

![img](assets/download_image-1733899968308.png) 

## 如何将一个线程不安全的集合转化为线程安全的集合

使用Collections类中的`synchronizedXxx()`方法 , 将线程不安全的集合传递进去, 就会返回线程安全的集合 

![img](assets/image-1733899997209.png) 

 底层使用的是装饰设计模式 , 对原生的集合进行增强 , 装饰方法中添加了`synchronized`保证线程安全

![img](assets/download_image-1733899999905.png)

## 你使用过的线程安全的集合有哪些（重点）

线程安全的集合有JUC很多 , 例如 : java.util.Concurrent

1. **ConcurrentHashMap**：高并发、高吞吐量的线程安全HashMap实现
2. **CopyOnWriteArrayList** : 线程安全的List，在读多写少的场合性能非常好
3. **ConcurrentLinkedQueue** : 高效的并发队列，使用链表实现。可以看做一个线程安全的LinkedList，这是一个非阻塞队列

## 说一下HashSet的实现原理

HashSet是基于HashMap实现的，HashSet的值存放于HashMap的key上，HashMap的value统一为present，因此 HashSet的实现比较简单，相关 HashSet 的操作，基本上都是直接调用底层 HashMap 的相关方法来完成，由于HashMap的键是不能重复的，所有HashSet 不允许重复的值。

## HashSet如何检查重复

HashSet是一个不允许存储重复元素的集合，它通过哈希表来实现。在HashSet中，每个元素都是唯一的，如果尝试添加一个已经存在的元素，HashSet会拒绝并保留原有的元素。

具体做法是在向HashSet中保存元素的时候，会先计算该元素的哈希值，然后确定这元素在数组中的位置，如果该位置上没有元素，则保存成功，如果有元素，则调用equals方法去跟存在的每个值进行比较，表较结果有一个相等，则直接丢弃；不相等，就会被挂在老元素的后面。

# 事务

## 事务的四大特性（重点）

事务的四大特性指的是原子性、一致性、隔离性、持久性

- 原子性：事务是最小的执行单位，不允许分割，同一个事务中的所有命令要么全部执行，要么全部不执行
- 一致性：事务执行前后，数据的状态要保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的
- 隔离性：并发访问数据库时，一个事务不被其他事务所干扰，各并发事务是独立执行的
- 持久性：一个事务一旦提交，对数据库的改变应该是永久的，即使系统发生故障也不能丢失

## 并发事务带来的问题（重点）

并发事务下，可能会产生如下的问题：

- 脏读：一个事务读取到了另外一个事务没有提交的数据
- 不可重复读：一个事务读取到了另外一个事务修改的数据
- 幻读（虚读）：一个事务读取到了另外一个事务新增的数据

## 事务隔离级别（重点）

事务隔离级别是用来解决并发事务问题的方案，不同的隔离级别可以解决的事务问题不一样

- 读未提交： 允许读取尚未提交的数据，可能会导致脏读、幻读或不可重复读
- 读已提交： 允许读取并发事务已提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生
- 可重复读： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生
- 可串行化： 所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，该级别可以防止脏读、不可重复读以及幻读。

上面的这些事务隔离级别效率依次降低，安全性依次升高，如果不单独设置，MySQL默认的隔离级别是可重复读

## 什么是分布式事务

在分布式系统中，一个业务因为跨越不同数据库或者跨越不同微服务而包含多个子事务，要求所有子事务同时成功或失败，这就是分布式事务。

比如一个电商系统的下单操作需要请求三个服务来完成，这三个服务分别是：订单服务，账户服务，库存服务

当订单生成完毕以后，就需要分别请求账户服务和库存服务进行进行账户余额的扣减和库存扣减。

假设都扣减成功了，此时在执行下单的后续操作时出现了问题，那么订单数据库就进行事务回滚，订单生成失败，而账户余额和扣减则都扣减成功了。

这就出现了问题，而分布式事务就是解决上述这种不一致问题的。

产生分布式事务的原因主要有下面几种：

- 跨库事务：一个应用某个功能需要操作多个库，不同的库中存储不同的业务数据
- 跨服务事务：一个应用某个功能需要调用多个微服务进行实现，不同的微服务操作的是不同的数据库

## 什么是CAP理论

在分布式系统有三个指标，分别是一致性、可用性、分区容错性

- 一致性(Consistency) ： 分布式系统中的更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致，不能存在中间状态


- 可用性(Availability) ： 分布式系统中提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果


- 分区容错性(Partition tolerance) ： 分布式系统在遇到任何网络分区故障时，仍然需要能够保证对外提供满足一致性和可用性的服务

CAP定理是指这个三个指标最多可以同时满足两个

## 为什么无法同时保证AC

对于分布式系统而言，各节点之间一定会存在网络交互，首先网络存在延迟，其次无法100%确保网络的可用，因此可以认为分区网络故障不可避免

在此条件下，如果要保证各节点的一致性，就必须在一个节点数据变更后同步给其他节点前，让客户等待，这就无法满足可用性

如果要保证各节点的可用性，就必须让各节点在接收到请求立即返回响应，那这个时候各节点可能还没有完成数据的统一，所以就违背了一致性

所以，在存在系统分区的场景下，可用性和一致性无法同时满足

## 什么是BASE理论

BASE是CAP理论的延伸，核心思想是即使无法做到强一致性，但应用可以采用适合的方式达到最终一致性。它的思想包含三方面：

- Basically Available （基本可用）：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。
- Soft State（软状态）：在一定时间内，允许出现中间状态，比如临时的不一致状态。
- Eventually Consistent（最终一致性）：虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致。

## 分布式事务的解决方案有哪些

分布式事物的解决方案有很多，常见的有2PC、TCC，还有可以使用MQ来做

**方案一：2PC**

2PC即两阶段提交，它是一种保证强一致性的处理方式。 主要将事务分为两个阶段：

- 阶段一: 表决阶段，所有参与者都将本事务执行预提交，并将能否成功的信息反馈发给协调者。
- 阶段二: 执行阶段，协调者根据所有参与者的反馈，通知所有参与者，步调一致地执行提交或者回滚。

**方案二：TCC**

TCC又称补偿事务，它是一种保证最终一致性的处理方式，一共有三个步骤：

- Try：做业务检查(一致性)及资源预留(隔离)，此阶段仅是一个初步操作，它和后续的Confirm一起才能真正构成一个完整的业务逻辑
- Confirm：做确认提交，Try阶段所有分支事务执行成功后开始执行Confirm
- Cancel：在业务执行错误需要回滚的状态下执行分支事务的业务取消，预留资源释放

**方案三：MQ分布式事务**

如果数据强一致性要求没那么高，可以采用消息中间件（MQ）实现事务最终一致。 

在支付系统中，常常使用的分布式事务解决方案就是基于MQ实现的，它对数据强一致性要求没那么高，但要求数据最终一致即可。

例如：向借呗申请借钱，借呗审核通过后支付宝的余额才会增加，但借呗和支付宝有可能不是同一个系统，这时候就可以借助MQ完成分布式事务

![image-20220824002222856](assets/image-20220824002222856.png) 

流程如下所示：

1、找借呗借钱

2、借呗借钱审核通过，同步生成借款单 

3、借款单生成后，向MQ发送消息，通知支付宝转账 

4、支付宝读取MQ消息，并增加账户余额

上图最复杂的其实是如何保障2、3在同一个事务中执行（本地事务和MQ消息发送在同一个事务执行），借款结束后，借呗数据处理就完成了，接下来支付宝才能读到消息，然后执行余额增加，这才完成整个操作。如果中途操作发生异常，例如支付宝余额增加发生问题怎么办？此时需要人工解决，没有特别好的办法，但这种事故概率极低。

## Seata的架构是什么

Seata事务管理中有三个重要的角色：

1、TC (Transaction Coordinator) -事务协调者：维护全局和分支事务的状态，协调全局事务提交或回滚。

2、TM (Transaction Manager) -事务管理器：定义全局事务的范围、开始全局事务、提交或回滚全局事务。

3、RM (Resource Manager) -资源管理器：管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。

如下所示：

![image-20220824002239492](assets/image-20220824002239492.png) 



## XA模式的工作流程是什么

xa模式整个工作流程图如下所示：

![image-20220824002258453](assets/image-20220824002258453.png) 

分为两个阶段：

1、RM一阶段的工作：① 注册分支事务到TC	② 执行分支业务sql但不提交	③ 报告执行状态到TC

2、TC二阶段的工作：TC检测各分支事务执行状态	①如果都成功，通知所有RM提交事务	②如果有失败，通知所有RM回滚事务

3、RM二阶段的工作：接收TC指令，提交或回滚事务

XA模式牺牲了可用性，保证了强一致性

## AT模型的工作原理是什么

at模式的整个工作流程图如下所示：

![image-20220824002317259](assets/image-20220824002317259.png) 

1、阶段一RM的工作：① 注册分支事务  ② 记录undo-log（数据快照）③ 执行业务sql并提交 ④报告事务状态

2、阶段二提交时RM的工作：删除undo-log即可

3、阶段二回滚时RM的工作：根据undo-log恢复数据到更新前

at模式牺牲了一致性，保证了可用性



## TCC模型的工作原理是什么

TCC模式与AT模式非常相似，每阶段都是独立事务，不同的是TCC通过人工编码来实现数据恢复。需要实现三个方法：

1、Try：资源的检测和预留； 

2、Confirm：完成资源操作业务；要求 Try 成功 Confirm 一定要能成功。

3、Cancel：预留资源释放，可以理解为try的反向操作。

Seata中的tcc模型的执行流程如下所示：

![image-20220824002343821](assets/image-20220824002343821.png) 

1、阶段一RM的工作：① 注册分支事务  ② 执行try操作预留资源  ④报告事务状态

2、阶段二提交时RM的工作：根据各分支事务的状态执行confirm或者cancel



# 框架

## Mybatis中#{}和${}的区别（重点）

在Mybatis中#{}和${}都可以用于在sql语句中拼接参数，但是在使用方面有很多的区别

- 处理方式不同：${}表示的是字符串拼接，Mybatis在处理它时，会直接将${}替换成变量的值

  而#{}是预编译处理，Mybatis在处理它时，会将sql中的#{}替换为?号，然后底层使用JDBC的预编译对象来赋值

- 安全性不同：${}存在SQL注入问题，#{}可以有效的防止SQL注入


- 效率不同：${}处理的sql到数据库每次都要重新编译，而#{}处理的sql只需要编译一次


总之，在实际使用过程中尽量使用#{}，而避免使用${}，当然这也不是说${}就没有使用场景

比如：如果sql中需要动态传递表名或者字段名，那就只能使用${}了


## MyBatis动态SQL了解吗

动态SQL是为了解决SQL语句灵活性不足的问题而提出的一种技术，它可以根据条件拼接SQL语句以不同的查询需求

MyBatis常用的动态SQL标签有：

1. 条件判断标签：if、choose、when、otherwise 当条件成立时才执行其中的SQL语句
2. 格式整理标签：trim、where、set 它可以在生成的SQL语句中调整格式，去除多余的关键字和符号
3. 循环遍历标签：foreach  它用于遍历一个集合并将集合中的元素添加到SQL语句中

## 谈谈对SpringIOC的理解（重点）

IOC也叫控制反转，是Spring用来解耦的一种设计思想，它的做法就是将对象的控制权由程序员手中反转到Spring手中

具体来说就是，在没有IOC之前，对象都是程序员在类中主动去创建，需要哪个创建哪个

有了IOC之后，对象会交给Spring容器创建和管理，如果哪个对象中需要其它对象属性，Spring也会自动完成依赖注入

总之一句话，IOC可以将对象的创建和对象之间依赖关系的维护交给Spring自动完成

## 谈谈对SpringAOP的理解（重点）

AOP，又叫面向切面编程，目的是将那些与业务无关，却为业务模块所共同调用的逻辑（例如事务处理、日志管理）封装起来，然后再动态插入到业务中

使用AOP可以减少系统的重复代码，降低模块间的耦合度，并有利于扩展和维护

SpringAOP是基于动态代理的，它底层同时支持JDK和CGLIB的代理方式，并且会根据被代理类是否有接口自动选择最合适的代理方式

我们在开发中用到AOP的主要使用场景有：事务管理、日志、性能监视、安全检查

## 你用过哪些Spring注解

我们常用的Spring注解主要分类下面几大类：

- 创建对象：@Component、@Controller、@Service

  它们都可以标注在自己开发的类上，Spring会使用注解标注的类创建出对象，然后放入容器

- 依赖注入：@Autowired

  标注在属性或者属性对应的set方法上，Spring会根据被标注属性的类型自动对属性进行赋值

- 配置类：@Configuration、@Bean

  主要标注在配置类中，用于声明配置类和向Spring容器中放入一些配置有关的对象

当然还有一些平时用的不是特别多的，比如：用于切面编程的@Around、@Pointcut等等

## Spring对象的作用域有几种

在Spring中作用域是用来对象的存活范围的，它支持5种作用域

- 第一种是单例，这是Spring中的对象的默认作用域，单例对象会跟随Spring容器创建而创建，跟随Spring容器销毁而销毁

- 第二种是多例，多例的对象在每次获取的时候才会创建，每次获取到的都是一个新的对象
- 还有三种分别是request、session和application，目前已经基本不再使用

其实，在我们平时的开发过程中，对象基本上都是配为单例的，这样可以有效的节省资源

## Spring中的对象线程安全吗

Spring中的对象主要分为单例对象和多例对象

多例对象每次获取都会创建新实例，也就是说线程之间不存在对象共享问题，也就不存在线程安全问题

单例对象是所有线程共享一个实例，因此就可能会存在线程安全问题，但是单例对象又分为无状态和有状态

- 无状态对象是指只对对象的成员变量进行查询操作，不会修改成员变量的值，因此不存在线程安全问题
- 有状态对象需要对对象中的成员变量进行数据更新操作，因此就可能存在线程安全问题

所以，最终我们得出结论，在Spring中只有有状态的单例对象才会存在线程安全问题

在企业开发过程中，处理有状态单例对象的线程安全问题主要采用ThreadLocal技术

也就是将可变成员变量保存在ThreadLocal中， ThreadLocal本身就具备线程隔离的特性，这就相当于为每个线程提供了一个独立的变量副本

每个线程只需要操作自己的线程副本变量，从而解决线程安全问题

## Spring的通知类型有哪些

Spring中的通知用于确定增强方法在切点的哪个位置执行，根据执行位置不同，Spring提供了五种通知：

1. 前置通知：增强方法在某切点之前执行
2. 返回后通知：增强方法在切点正常完成后执行
3. 抛出异常后通知：增强方法在切点抛出异常退出时执行
4. 后置通知：增强方法在切点退出的时候执行的通知（不论是正常返回还是异常退出）
5. 环绕通知：包围一个切点的通知

## Spring的事务管理方式有哪些（重点）

Spring支持编程式事务和声明式事务

- 编程式事务指的是在代码中使用try-catch捕获异常，然后配合事务的api来手动处理事务问题

  这种方式的缺点是代码耦合，复用性低，优点是可以精确控制要增强的代码（不仅仅限于方法粒度）

- 声明式事务是AOP思想的一种应用，它的核心思想是将业务方法作为切点

  将事务处理方法作为增强，通过动态代理实现事务的管理，它的优点是降低代码耦合，提供复用; 缺点是无法精确控制要增强的代码

## Spring事务传播行为有几种（重点）

事务传播行为是为了解决业务层方法之间互相调用的事务问题，当事务方法被另一事务方法调用时，需要指定事务应该如何传播

例如：方法可能继续在现有事务中运行，也可能开启一个新事务，并在自己的事务中运行

Spring支持7个种事务传播行为的：

1. 必须事务：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务

2. 必须新事务：创建一个新的事务，如果当前存在事务，则把当前事务挂起

3. 强制事务：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常

4. 支持事务：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行

5. 不支持事务：以非事务方式运行，如果当前存在事务，则把当前事务挂起

6. 强制无事务：以非事务方式运行，如果当前存在事务，则抛出异常

7. 嵌套事务：如果当前存在事务，则创建一个当前事务的嵌套事务来运行；如果当前没有事务，则创建一个事务

   嵌套事务是已存在事务的一个子事务，嵌套事务开始执行时，将取得一个保存点，如果这个嵌套事务失败，将回滚到此保存点

   嵌套事务是外部事务的一部分，只有外部事务结束后它才会被提交

## 声明式事务是如何实现的（重点）

Spring的声明式事务底层是基于数据库事务和AOP机制的

首先Spring会为使用了@Transactional注解的Bean代理对象，当调用代理对象的方法时，会先判断该方法上是否加了@Transactional注解

如果加了，那么则利用事务管理器创建一个数据库连接，并且禁止此连接的自动提交事务

然后执行当前方法，方法中会执行sql ，执行完当前方法后，如果没有出现异常就直接提交事务；

如果出现了异常，并且这个异常是需要回滚的就会回滚事务，否则仍然提交事务。

Spring事务的隔离级别对应的就是数据库的隔离级别 ，Spring事务的传播机制是基于数据库连接来做的，一个数据库连接一个事务

如果传播机制配置为需要新开一个事务，那么实际上就是重新建立一个数据库连接，在此新数据库连接上执⾏sql

## Spring中的设计模式有哪些

- 工厂模式：Spring使用工厂模式通过BeanFactory和 ApplicationContext创建bean对象
- 单例模式：Spring 中的bean默认都是单例的
- 代理模式：Spring 的AOP功能用到了JDK的动态代理和CGLIB字节码生成技术
- 模板方法：用来解决代码重复的问题。比如 RestTemplate、jdbcTemplate、 JpaTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式
- 观察者模式： Spring 事件驱动模型就是观察者模式很经典的一个应用。定义对象键一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都会得到通知被制动更新，如 Spring 中 listener 的实现 ApplicationListener

## Spring的对象生命周期（重点）

Spring中对象的生命周期指的就是对象从创建到销毁要经历的过程，主要分为这样几步：

- 第一步是创建对象，其实就是Spring调用类的构造函数创建出bean的过程

- 第二步是对象的依赖注入，也就是给对象中的属性进行赋值的过程

- 第三步是处理Aware接口，如果一个类实现了Spring提供的几个Aware接口，此过程就会执行到类中重写的方法

- 第四步是调用BeanPostProcessor，它会在自定义的初始化方法之前执行

- 第五步是调用自定义初始化方法，比如实现了接口InitializingBean或者使用@PostContruct标注自定义方法

- 第六步是调用BeanPostProcessor，它会在自定义的初始化方法之后执行，用于对bean进行增强，有可能在这里产生代理对象

- 最后一步是销毁bean了

<img src="assets/image-20241209151536261.png" alt="image-20241209151536261" style="zoom:67%;" /> 

~~~java
public class UserController implements BeanNameAware{
    
    @Autowired
    private UserService userService;
    
    //
    Aware系列方法(){
    	获取到spring中刚刚创建好对象的名
	}
    
    @PostContruct
    自定义初始化方法(){
        
    }
}


UserController userController = new UserController(UserService);

//1. 实例化 -- 创建对象 -- new
UserController userController = new UserController();

//2. 初始化 -- 对象属性赋值 -- setUserService(UserService userService) / UserController(UserService userService)
userController.setUserService(userService)
~~~

## Spring是如何解决循环依赖的

循环依赖其实就是两个或两个以上的bean互相持有对方，最终形成闭环的现象。Spring框架是使用三级缓存来解决大部分循环依赖问题的

- 一级缓存用来存储已经经历了完整的生命周期的bean对象
- 二级缓存用来存储早期的bean对象，也就是那些创建成功但是还没有初始化成功的bean对象（生命周期还没走完）

- 三级缓存存储的是对象工厂，他们是用来创建某个对象的


具体的流程是这样的，比如有A和B两个对象构成了循环依赖

1. 先实例A对象，同时会创建A的工厂对象放入三级缓存 

2. 接下来开始A的初始化，这时候需要B对象，走B的创建的逻辑

3. B创建完成后，也会创建B的工厂对象放入三级缓存，然后开始b的初始化

4. 此时需要A对象，通过三级缓存中获取A的工厂对象来生成一个A的对象同时存入二级缓存

   这个是有两种情况，一个是可能是A的普通对象，另外一个是A的代理对象，都可以让A的工厂对象来生产

5. B通过从通过二级缓存获得到A的对象后可以正常注入，B创建成功，存入一级缓存

6. 回到A对象初始化，因为B对象已经创建完成，则可以直接注入B，A创建成功存入一次缓存

7. 最后将二级缓存中的临时对象A清除 

## SpringMVC执行流程

<img src="assets/image-20241209202553727.png" alt="image-20241209202553727" style="zoom:67%;" /> 

具体流程如下所示：

1. 用户发送出请求到前端控制器DispatcherServlet
2. 前端控制器收到请求调用HandlerMapping（处理器映射器）
3. HandlerMapping找到具体的处理器(可查找xml配置或注解配置)，生成处理器对象及处理器拦截器(如果有)，再一起返回给DispatcherServlet
4. DispatcherServlet调用HandlerAdapter（处理器适配器）
5. HandlerAdapter经过适配调用具体的处理器（Handler/Controller）
6. Controller执行完成返回ModelAndView对象。
7. HandlerAdapter将Controller执行结果ModelAndView返回给DispatcherServlet
8. DispatcherServlet将ModelAndView传给ViewReslover（视图解析器）
9. ViewReslover解析后返回具体View（视图）
10. DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）
11. DispatcherServlet响应用户

![image-20241209202936806](assets/image-20241209202936806.png) 

具体流程如下所示：

1. 用户发送出请求到前端控制器DispatcherServlet
2. DispatcherServlet收到请求调用HandlerMapping（处理器映射器）
3. HandlerMapping找到具体的处理器，生成处理器对象及处理器拦截器(如果有)，再一起返回给DispatcherServlet
4. DispatcherServlet调用HandlerAdapter（处理器适配器）
5. HandlerAdapter经过适配调用具体的处理器（Handler/Controller）
6. 方法上添加了@ResponseBody
7. 通过HttpMessageConverter来返回结果转换为JSON并响应

## SpringMVC的常用注解有哪些

- 创建对象放入容器：@Controller、@RestController

  区别在于后者还可以将返回的集合或对象转换为JSON直接返回

- 设置请求路径：@RequestMapping、@GetMapping、@PostMapping 、@PutMapping、@DeleteMapping

​       第一个是通用的，可以接收各种类型的请求；后面四个只能直接对应类型的请求

- 接收请求参数：

  @RequestBody： 接收请求体中的json数据

  @PathViriable：接收请求路径中的参数

  @RequestHeader：接收请求头中的参数

  @RequestParam：一般用于给参数设置默认值或者完成请求参数和controller方法参数的映射

## SpringMVC如何处理统一异常

SpringMVC的异常处理底层是通过AOP实现的，它的核心思想是将异常处理的代码和业务逻辑代码分离开来

使用它之后，我们在自己的业务代码中不需要在处理异常，有异常直接就上抛到框架中

框架就会将异常交给自定义的全局异常处理器中统一处理

自定义全局异常处理器，会用到两个注解：

1. @RestControllerAdvice  标注在类上，声明被标注的类是一个用于专门处理异常的类
2. @ExceptionHandler 标注在异常处理类中的方法上，声明被标注的方法可以处理哪些异常

## SpringBoot的自动装配原理（重点）

SpringBoot自动装配主要是基于注解编程和约定优于配置的思想来进行设计的

自动装配就是自动地把其他组件中的Bean装载到IOC容器中，不需要开发人员再去配置文件中添加大量的配置

我们只需要在SpringBoot的启动类上添加一个@SpringBootApplication的注解，就可以开启自动装配

SpringBootApplication底层最重要的一部分是@EnableAutoConfiguration这个注解来实现的，它作用是：

1. 读取所有jar包/META-INF/spring.factories文件中EnableAutoConfiguration键对应的值
2. 这些值必须声明为Spring的配置类，也就是在类中需要向Spring容器放入对象
3. 为了防止非当前所需的组件进入到容器，配置类中需要使用@Conditional注解来声明配置成立的必要条件

## SpringBoot中starter的作用

当项目足够复杂时，因为涉及的组件太多了，就需要引入很多的依赖，此时管理依赖就边的很麻烦

此时SpringBoot的starter就派上用场了，每个starter都可以为我们提供某个服务场景所需要的一系列依赖

在导入starter之后，SpringBoot主要帮我们完成了两件事情：

1. 相关组件的自动导入
2. 相关组件的自动配置

## SpringBoot加载配置的方式

SpringBoot支持很多种方式加载配置，常见有

1. 配置文件，直接在项目中提供SpringBoot支持的配置文件，比如properties、yaml 、yml
2. 系统环境变量，SpringBoot是可以读取系统环境变量中的配置信息的，但不推荐这么做
3. 命令行参数，SpringBoot在项目启动的时候运行通过命令行直接传递参数，一般用于临时修改配置的情况

## SpringBoot读取配置的方式

SpringBoot常见的读取配置信息的方式有两种：

1. 使用@Value配合EL表达式（@Value("${name}")）注解直接注入对应的值

2. 使用@ConfigurationProperties注解把对应的值绑定到一个配置对象，然后将配置对象注入到需要的地方

推荐使用使用第二种方式，在配置比较多的情况下，操作简单，可读性好

## SpringCloud组件有哪些（重点）

我们项目中采用的是SpringCloud和SpringCloudAlibaba相结合的方式，也就是采用了Nacos作为服务注册中心和配置中心

使用了OpenFeign作为服务调用组件，使用了Gateway来做服务网关，使用了Sentinel来做服务的保护

![image-20241210133105077](assets/image-20241210133105077.png) 

## SpringCloud两个配置文件

SpringCloud支持两个配置文件，分别是：bootstrap.yml和application.yml

1. boostrap比applicaton优先加载，在应用程序上下文的引导阶段生效，且里面的属性不能被覆盖，一般来说我们在此文件中配置Nacos的连接地址

2. application用于SpringBoot项目的自动化配置，一般来说我们会将自己项目的业务配置项写在这里面

## 如何解决服务雪崩

服务雪崩是指在一个分布式链路中，由于一个服务失败，进而导致跟其相关的服务阻塞，最终导致整条链路的服务都失败的情形

在我们的项目中，解决服务雪崩的方案有服务限流、线程隔离、服务熔断、服务降级等等

- 服务限流是指对超出服务处理能力之外的请求进行拦截，对访问服务的流量进行限制，以保证服务不会被大流量压垮

- 线程隔离是指给每个调用者的请求分配独立线程池，出现故障时，最多消耗这个线程池内资源，避免把调用者的所有资源耗尽

- 服务降级是指当下游服务调用失败时，调用自身提供的备用逻辑

- 服务熔断是指当一个调用者发现下游服务故障率得到一定阈值时，会有一段冷却时间，在这段时间内，就不再向其发送请求，而是走降级逻辑，

  冷却时间过后，会放过一个请求到下游，如果下游正常了，就断开熔断正常访问；如果下游依旧不正常，则继续熔断

## 什么是断路器（重点）

断路器是用来实现服务熔断的一种机制，它主要有三个状态：

- 关闭状态，断路器放行所有请求，并开始统计异常比例、慢请求比例，超过阈值则切换到打开状态
- 打开状态，服务调用会被熔断，访问被熔断服务的请求会被拒绝，直接走降级逻辑，此状态维持一段时间后会进入半开状态
- 半开状态，放行一次请求到下游服务，如果请求成功，则切换到关闭状态；如果请求失败，则切换到打开状态

<img src="assets/image-20220520113844464.png" style="zoom:67%;" /> 

## 实现线程隔离的手段

实现线程隔离的手段主要有两种：一种是线程池隔离，一种是信号量隔离

- 线程池隔离指的是每一个被隔离的业务都要创建一个独立的线程池，它的优点是隔离性强，缺点是cpu开销大，Hystix采用的是此方式
- 信号量隔离指的是不使用线程而是直接采用一个信号量计数器来控制可发送请求的数量，它的特点性能好，Sentinel采用的是此方式

![image-20241209191105330](assets/image-20241209191105330.png) 

## 流量控制算法有哪些

Sentinel提供多种流量控制算法 ，包括：滑动窗口算法、令牌桶算法以及漏桶算法等

- 滑动窗口算法：

  这是一种用于统计单位时间内请求次数的方法，它将时间划分为多个小的时间窗口，并在每个小窗口内记录请求的数量

  当新的请求到来时，系统会检查当前小窗口内的请求数量是否超过了预设的阈值，如果超过则拒绝请求

- 令牌桶算法：

  它的核心思想是一个桶中存储了一定数量的令牌，程序会以固定的速率生成令牌，存入令牌桶中，如果令牌桶满了以后，停止生产

  每当有请求到达时，就需要从桶中取出一个令牌，如果没有足够的令牌，则请求被延迟或拒绝

  在使用令牌桶算法时，可能会存在突发流量导致系统过载，所以尽量不要将令牌上限设定到服务能承受的QPS上限

- 漏桶算法：

  请求到达后不是直接处理，而是先放入一个队列，然后以固定的速率从队列中取出并处理请求

## Feign工作原理

Feign是SpringCloud技术栈中用于远程调用的一个HTTP客户端，主要作用是将远程服务调用格式本地方法调用格式统一成一致的

Feign的工作步骤如下：

1. 首先需要在SpringBoot的启动类上添加@EnableFeignClients注解开启对Feign的支持

2. 当程序启动时，会扫描所有标有@FeignClient的注解的类，并且将这些信息注入Spring容器中
3. 当定义的Feign接口中的方法被调用时，通过JDK的代理方式，来生成具体的RequestTemplate
4. RequestTemplate对象封装了HTTP请求需要的全部信息，如请求参数名，请求方法等信息
5. 然后RequestTemplate生成Request，并将Request交给Client去处理，这里的Client可以是JDK原生的URLConnection、Apache的HttpClient等
6. 最后Client被封装到LoadBalanceClient类，这个会结合负载均衡算法发起服务之间的调用

## Nacos的工作原理（重点）

Nacos是SpringCloudAlibaba技术栈的一项技术，在项目中主要用作服务注册中心和服务配置中心

Nacos做服务注册中心主要具备下面这些能力

- 服务注册：服务提供者会将自己的地址信息注册到Nacos中，在nacos中形成一张服务清单

- 服务发现：服务消费者会从Nacos中查询服务提供者的信息，并且缓存到本地，并且每隔30s更新一次

  当服务提供者的地址发生变化之后，Nacos也会主动推送最新的地址信息给消费者

- 服务续约：服务提供者会间隔一定时间就给Nacos发送心跳，表明自己在线

- 服务剔除：当nacos一段时间内接收不到服务微服务的续约请求时或者收到微服务的下线请求时，就会将服务地址从服务清单中删除

Nacos做服务配置中心的原理

1. Nacos允许微服务将经常改动的一些配置项保存到Nacos中，然后在本地的bootstrap.yml中指定远程配置的位置信息
2. 一旦Nacos的配置发生变化之后，会主动推送给微服务，微服务进行热更新
3. Nacos还支持使用多环境、命名空间的方式实现多套配置文件的共存

## Getway的功能是什么（重点）

在我们项目中，Gateway的作用是服务网关，它是前端请求到后端服务的统一入口，通过网关实现下边的功能：

- 请求路由，根据请求路径将请求转发到不同的应用服务器
- 负载均衡，通过负载均衡算法将请求转发到不同的应用服务器
- 用户身份鉴权，校验用户身份及用户的权限

# MQ(*)

## RabbitMQ支持的消息类型有哪些（重点）

RabbitMQ主要支持两大类消息类型，分别是点对点和发布订阅

- 点对点指的是生成者发送的同一条消息只能被一个消费者所消费
- 发布订阅指的是生成发送的同一条消息可以被多个消费者所消费

在点对点这种模型下，根据消费者的数量又分为Simple和Work两种类型：Simple指的是一个消费者，Work指的是多个消费者

在发布订阅这种模型下，根据交换机类型的不同分为Fanout、Direct、Topic三种模式

- Fanout类型的交换机会将接收到的消息转发到所有与之绑定的队列上

- Direct类型的交换机会根据消息的routingKey与队列绑定时声明的bindingKey比对，比对成功再转发消息
- Topic类型就是在Direct类型的基础上支持了bindingKey的模糊写法，通常使用*表示一个单词，使用#表示任意个单词

## 你了解的消息中间件有哪些

消息中间件在项目中通过作为解耦合的一种异步消息传送媒介所存在，我了解主要有下面几个

- 第一个是RabbitMQ，它性能和安全性都很好，延迟也低，适用于一般的企业级项目
- 第二个是RocketMQ，它一般是电商项目的首选
- 第三个是Kafka，它的主要优点是吞吐量比较大，一般应用在大数据领域
- 还有一个就是ActiveMQ，这是一个非常老牌的消息中间件，对比其它三个来讲，性能比较低，近几年来已经很少使用了

## 使用RabbitMQ如何保证消息不丢失（重点）

消息从生产者发送到消费者接收会经历多个过程 , 其中的每一步都可能导致消息丢失 ，大体可以分为这样几种情况:

1. 消息在发送到mq过程中丢失
2. 消息在mq中丢失
3. 消费者消费消息失败 

针对每一步，RabbitMQ分别给出了解决方案：

1. 为了解决消息在发送到mq过程中丢失，MQ提供了生产者重连机制和生产者确认机制

   生产者重连机制指的是当由于网络抖动导致生产者暂时无法连接mq时，会进行自动重连

   生产者确认机制指的是消息发送到mq的过程中如果出现问题，会触发失败回调方法，通知生产者失败原因

2. 为了解决消息在mq中丢失，MQ提供了持久化和惰性队列

   MQ允许开启交换机持久化、队列持久化、消息持久化，以保证消息在传输过程中不会丢失

   MQ还支持开启惰性队列，以提高消息的存储量

3. 为了解决消费者无法消费消息，MQ提供了消费者确认机制和消息重试机制

   消费者确认机制指的是只有当消费者一方确认消息消费成功了，mq才删除消息，否则就会重新发送消息

   但是这种重试机制会导致消息在MQ中频繁的出队入队，因此我们一般会使用Spring提供的本地重试，当然重试也要有一定的次数

   如果超过了指定的重试次数，我们需要将消息转到一个指定的交换机和队列中，后期人工介入

>以下为拓展内容

通过RabbitMQ本身所提供的机制基本上已经可以保证消息不丢失, 但是因为一些特殊的原因还是会发送消息丢失问题 ,

例如 : 回调丢失 , 系统宕机, 磁盘损坏等 , 这种概率很小 , 但是如果想规避这些问题 , 进一步提高消息发送的成功率, 也可以通过程序自己进行控制

![image-20220828234538133](assets/image-20220828234538133.png) 

设计一个消息状态表 , 主要包含 : 消息id , 消息内容 , 交换机 , 消息路由key , 发送时间, 签收状态等字段 

发送方业务执行完毕之后 , 向消息状态表保存一条消息记录，消息状态为未签收 , 之后再向MQ发送消息 ,

消费方接收消息消费完毕之后 , 向发送方发送一条签收消息 , 发送方接收到签收消息之后 , 修改消息状态表中的消息状态为已签收

之后通过定时任务扫描消息状态表中这些未签收的消息 , 重新发送消息, 直到成功为止 , 对于已经完成消费的消息定时清理即可

## 消息的重复消费问题如何解决的(幂等性)（重点）

在使用RabbitMQ进行消息收发的时候，如果发送失败或者消费失败会自动进行重试，那么就有可能会导致消息的重复消费 

解决方案可以使用：唯一消息ID+Redis

具体做法就是：当消费者接收到一条消息之后，首先使用redis的setnx命令尝试向redis中插入消息的唯一id

如果保存成功，说明此条消息没有被消费过，可以正常消费

如果保存失败，说明这条消息已经执行过消费逻辑，则不能进行再次消费

## RabbitMQ如何设置消息过期

RabbitMQ设置消息过期的方式有两种 : 

1. 在队列上设置过期时间，所有进到这个队列的消息就会具有统一的过期时间

2. 为消息单独设置过期时间

如果队列过期和消息过期同时存在 , 会以时间短的时间为准

# ES(*)

## 什么是倒排索引（重点）

倒排索引是搜索引擎的核心，它可以将用户从词条导向文档，主要目标是快速从数百万文件中查找数据

倒排索引主要体现在文档的保存和查询流程中

- 保存文档时，会先根据文档进行分词，然后使用分好的词条作为key进行排序，然后将文档的标识作为value进行存储

- 查询文档时，也会先对查询关键字进行分词，然后根据分好的词条直接定位相关文档，再做结果的合并

## 如何保证ES和MySQL的数据一致性

保证MySQL和ES数据一致性的方式有很多，下面列举几个：

1. 同步双写：程序在向MySQL写入数据之后，立即将数据写入ES中。这种方法可以确保数据的实时同步，但可能会增加系统的复杂性和延迟。
2. 异步消息：程序在在向MySQL写入数据之后，向MQ中投递消息，ES相关程序监听MQ，获取数据，写入ES
3. canel监听：使用canel监听MySQL的binlog，当发现写入操作后，立即读取内容，写入ES

## ES中的查询关键字有哪些

在ES中用于声明查询条件的关键字主要有：

- match_all：查询所有

- match、multi_match：全文检索

- term：精准词条查询

- range：范围查询

- bool、must、must_not、should、filter：复合查询

还有一些跟地理位置、相关性算分相关的

## ES中字符串类型有几个

ES有两个字符串类型，分别是：keyword 和 Text，他们两个的区别主要是在分词方面

- keyword类型的字符串是不会分词的，直接根据字符串内容建立倒排索引
- Text类型的字符串在保存到ES时会先分词，然后根据分词后的内容建立倒排索引

## ES中query和filter的区别

query和filter都可以实现ES中的查询，区别是

- query查询操作不仅仅会进行查询，还会计算分值，用于确定相关度
- filter查询操作仅判断是否满足查询条件，不会计算任何分值，也不会关心返回的排序问题，同时，filter查询的结果可以被缓存，提高性能。

# MySQL(*)

## 内、外连接的区别 

内连接和外连接都是数据库进行多表联查时使用的连接方式，区别在于二者获取的数据结果集不同

内连接指的是使用左表中的每一条数据分别去连接右表中的每一条数据，仅仅显示出匹配成功的那部分

外连接有分为左外连接和右外连接

- 左外连接: 首先要显示出左表的全部，然后使用连接条件匹配右表，能匹配中的就显示，匹配不中的显示为null
- 右外连接: 首先要显示出右表的全部，然后使用连接条件匹配左表，能匹配中的就显示，匹配不中的显示为null

![image-20241205110447516](assets/image-20241205110447516.png) 

## drop、delete、truncate区别

这个关键字都是MySQL中用于删除的关键字，区别在于：

1. delete语句执行删除的过程是每次从表中删除一行
2. drop主要用于删除整个数据表及其数据
3. truncate是直接把表删除，然后再重建表结构

这三种方式在效率方面：drop最高、truncate 其次、delete最低，但是drop和truncate都不记录日志，无法回滚

## union与union all的区别

union和union all都是MySQL中用于合并多条select语句结果的关键字，它会将前后两条select语句的结果组合到一个结果集中

区别在于UNION ALL会返回所有结果，UNION会去掉重复的记录

## char和varchar的区别

char和varchar是MySQL中的字符串类型，区别在于下面几方面：

1. 最大长度：char最大长度是255字符，varchar最大长度是65535个字节
2. 占用长度：char是定长的，不足的部分用隐藏空格填充，varchar是不定长的
3. 空间使用：char会浪费空间，varchar会更加节省空间
4. 查找效率：char查找效率会很高，varchar查找效率会更低

因此我们如果存储固定长度的列，例如身份证号、手机号建议使用char

其它不定长度的建议使用varchar，使用varchar的时候也要尽量让声明长度贴近实际长度

> 注意：varchar(50)中50的涵义是最多存放50个字符，varchar(50)和varchar(200)存储hello所占空间一样

## 数据库三大范式

三大范式是指导设计数据库的原则

- 第一范式：表中的每一列不能再进行拆分，也就是每一列都应该是原子的
- 第二范式：一张表只做一件事，不要将多个层次的数据列保存到一张表中
- 第三范式：数据不能存在传递关系，也就是说可以通过其它字段推出来的字段没必要再存储

在现有的程序设计中认为第三范式是可以不遵守的，也就是通过添加冗余字段，来减少多表联查或计算，我们称为反三范式

## 索引的分类

索引是数据库中用于提高查询效率的一种手段

* 从物理存储角度上分为聚簇索引和非聚簇索引

  聚簇索引就是将数据与索引放在一起，找到索引即找到了数据。对于聚簇索引，其非叶子节点上存储的是索引字段的标识(id)，而叶子节点上存储的是对应记录的整行数据

  非聚簇索引是指将索引与数据分开存储的一种方式。在非聚簇索引中，叶子节点包含索引字段的值以及指向数据行的逻辑指针

* 从逻辑角度上分为普通、唯一、主键和联合索引，它们都可以用来提高查询效率，区别点在于

  唯一索引可以限制某列数据不出现重复，主键索引能够限制字段唯一、非空

  联合索引指的是对多个字段建立一个索引，一般是当经常使用某几个字段查询时才会使用，它比对这几个列单独建立索引效率要高

## 索引的创建原则（重点）

索引可以大幅度提高查询的效率，但不是所有的字段都要加，也不是加的越多越好，因为索引会占据磁盘空间，也会影响增删改的效率

我们在建立索引的时候应该遵循下面这些原则：

1. 主键、外键应该建立索引
2. 经常作为查询条件、排序、分组、聚合统计的字段应该建立索引

3. 经常使用多个条件查询时建议使用组合索引代替多个单列索引

除此之外，下面这些情况不应该建立索引

1. 数据量小的表不建议添加索引
2. 数据类型的字段是TEXT、BLOB等数据类型的字段不建议建立索引
3. 不要在区分度低的字段建立索引，比如性别字段、年龄字段等

## 索引失效的情况（重点）

索引失效指的是虽然在查询的列上添加了索引，但是某些情况下，查询的时候依旧没有用到索引，常见的情况有

1. 使用like关键字时，模糊匹配使用％开头，会导致索引失效
2. 使用OR连接条件时，如果条件中存在没有索引的，会导致索引失效
3. 在索引列上进行计算、函数运算、类型转换，会导致索引失效
4. 字符串做值时不加单引号，会导致索引失效
5. 联合查询的时候不满足最左匹配原则，会导致索引失效

## 如何知道索引是否失效（重点）

MySQL中自带了一个关键字叫explain，它可以加在一个sql的前面来查看这条sql的执行计划

在执行计划中，我们主要观察两列的结果，一列是type，一列是extra

第一个type是重要的列，可以看到索引的使用情况，从最好到最差的连接类型为：const > eq_ref > ref  > range > index > all

- const：索引一次就能得到结果，一般是使用唯一索引或者主键作为条件
- eq_ref：出现两表关联查询中，驱动表只返回一行数据，也就是关联条件为主键或唯一列
- ref：出现两表关联查询中，查询条件走普通索引，只要使用相等条件检索时就可能出现
- range：在索引中检索指定范围的行，常见于使用>，<，between，in，like等运算符的查询中
- index：全表扫描索引文件返回符合要求的记录
- all：全表扫描数据文件返回符合要求的记录

我们在优化的时候尽量优化到range级别以上

除了type之外我们需要关注一下extra列，它表示执行状态说明

- 要保证此列不要出现using filesort、using temporary等使用临时表或外部文件的情况


- 如果出现Using index最好了，它表示列数据仅仅使用了索引中的信息而没有回表查询


## MyISAM和InnoDB的区别（重点）

MyISAM和InnoDB是目前MySQL中最为流行的两种存储引擎，它们的区别有这几方面：

1. MyISAM不支持事务和外键，每次操作都是原子的；InnoDB支持事务和外键

2. MyISAM仅仅支持表级锁，即每次操作是对整个表加锁；InnoDB支持行级锁，因此可以支持写并发

3. MyISAM的数据和索引不在同一个文件中；InnoDB的数据和索引在同一个文件中

4. MyISAM中主键和非主键索引的数据部分都是存储的文件的指针，也就是非聚簇索引；

   InnoDB主键索引的数据部分存储的是表记录，也就是属于聚簇索引；非主键索引的数据部分存储的是主键值，也就是属于非聚簇索引

## 聚簇索引和非聚簇索引（重点）

聚簇索引简单理解就是将数据与索引放在一起，找到索引即找到了数据。对于聚簇索引，其非叶子节点上存储的是索引字段的值，而叶子节点上存储的是对应记录的整行数据

非簇簇索引是指将索引与数据分开存储的一种方式。在非聚簇索引中，叶子节点包含索引字段的值以及指向数据页的逻辑指针

聚簇索引选取规则:

- 如果存在主键，主键索引就是聚集索引
- 如果不存在主键，将使用第一个唯一（UNIQUE）索引作为聚集索引
- 如果表没有主键，或没有合适的唯一索引，则会自动生成一个rowid作为隐藏的聚集索引

<img src="assets/image-20241204225555611.png" alt="image-20241204225555611" style="zoom:70%;" /> 

## 什么是回表

在MySQL的B+树中，聚簇索引的叶子节点直接包含了我们要查询的整行数据，而非聚簇索引的叶子节点则包含了主键的值

因此，当我们通过非聚簇索引进行查询时，首先会通过非聚簇索引查找到主键的值，然后需要再通过主键的值进行一次查询才能获取到我们要查询的数据，这个过程称为回表

回表就需要增加一次查询，因此我们应该尽量通过覆盖索引来减少回表的次数

<img src="assets/image-20241204225736777.png" alt="image-20241204225736777" style="zoom:67%;" /> 

id  age  name

select id,name,age from user where name = 'Arm'

select id from user where  name = 'Arm'

select * from user where id = 上次结果



## 什么是覆盖索引

覆盖索引是指查询语句使用到了索引，并且查询的所有内容都在索引中，不需要进行回表查询

<img src="assets/image-20241204230257605.png" alt="image-20241204230257605" style="zoom:67%;" /> 

## 索引的数据结构是什么

在MySQL中索引使用的数据结构是B+Tree，B+树是基于B树的变种，它具有B树的平衡性，而且树的高度更低

- B+树非叶子节点不存数据只存索引的标识和指针，因此其内部节点相对B树更小，树的高度更低，查询产生的I/O更少
- B+树查询效率更高，B+树使用双向链表串连所有叶子节点，区间查询效率更高
- B+树查询效率更稳定，B+树每次都必须查询到叶子节点才能找到数据，而B树查询的数据可能不在叶子节点，也可能在，这样就会造成查询的效率的不稳定

## 数据库中的锁有哪些

MySQL中的锁从不同维度可以分为不同的种类

1. 从锁的粒度上可以分为表锁和行锁

   表锁指的是会锁定修改数据所在的整个表，锁定粒度大，发生锁冲突概率高

   行锁指的是会锁定修改数据所在的行记录，锁定粒度小，发生锁冲突概率低

2. 从锁的排他性上分为共享锁和排他锁

   共享锁指的是当一个事务针对同一份数据加上共享锁之后，另一个事务可以读数据，不能改数据，但是可以再往上加一把共享锁

   对索引列加共享锁，锁定的是一行数据；对非索引列加共享锁，锁定的是整表数据

   排他锁指的的是当一个事务针对同一份数据加上排他锁之后，另一个事务可以读数据，不能改数据，也不能再上其它任何锁

   ~~~sql
   select ... lock in share mode  -- 共享锁
   select ... for update  --排他锁
   ~~~

3. 还有两种概念上的锁是悲观锁和乐观锁

   悲观锁是指一个事务在修改数据的时候，总是认为别人也会修改此数据，所以强制要使用锁来保证数据安全

   乐观锁是指一个事务在修改数据的时候，总是认为别人不会修改此数据，因为不加任何锁

   这种情况下万一在当前事务修改的时候，数据被其它事务也修改了，就会出现问题，此时常用的方案是： CAS

   给数据表中添加一个version列，每次更新后都将这个列的值加1，读取数据时，将版本号读取出来

   在执行更新的时候，会先比较版本号，如果相同则执行更新，如果不相同，说明此条数据已经发生了变化，就放弃更新或重试

## MySQL主从复制的流程

主从复制用于MySQL主从集群的主节点向从节点同步数据，主要是依靠MySQL的binLog实现的，大体流程分为三步：

1. Master主库在事务提交时，会把数据变更记录在二进制日志文件BinLog中
2. 从库读取主库的二进制日志文件Binlog ，写入到从库的中继日志RelayLog 
3. slave重做中继日志中的事件，将改变反映它自己的数据

<img src="assets/image-20220911213148696.png" style="zoom:80%;" /> 

## MySQL日志类型

MySQL的很多功能都是依靠日志来实现的，比如事务回滚、数据备份、主从复制等等，常见的日志有下面几个：

1. binlog 归档日志

   负责记录对数据库的写操作，一般用在主从复制过程中记录日志，从库拷贝此日志做重放实现数据同步

2. undolog 回滚日志

   保存了事务发生之前的数据的一个版本，可以用于回滚

3. redolog 重做日志

   用于确保事务的持久性，防止在发生故障的时间点，尚有脏页未写入磁盘

   在重启mysql服务的时候，根据 redolog 进行重做，从而达到事务的持久性这一特性

## 谈谈你对sql的优化的经验（重点）

我在企业中优化Sql大体分为三步：

1. 查找问题sql，主要手段是开启mysql的慢查询日志，它会将执行时间较长的sql记录记录下来
2. 找到sql之后，我会分析出现问题的原因，原因很多，主要字段类型选择错误、sql语句效率低、索引失效等等
3. 根据问题不同，我会再去定具体的解决方案

简单给您说几个常见的把

1. 确定选择的引擎是否合适

   myisam适合于查询为主，增删较少，无事务要求的数据表

   Innodb适用于有事务处理，或者包括很多的更新和删除的数据表

2. 表设计是否合理

   单表不要有太多字段，建议在20以内

   合理的加入冗余字段可以提高查询速度

3. 确定字段的数据类型是否合适

   数值型字段的比较比字符串的比较效率高得多，字段类型尽量使用最小、最简单的数据类型

   设置合适的字符串类型（char和varchar）char定长效率高，varchar可变长度，效率稍低，varchar的长度只分配真正需要的空间

   尽量使用TIMESTAMP而非DATETIME，尽量设计所有字段都得有默认值，尽量避免null

4. 确定sql的书写是否有的题

   SELECT语句务必指明字段名称，避免直接使用select * 

   SQL语句中IN包含的值不应过多

   可以用内连接，就尽量不要使用外连接

   使用连接连接查询来代替子查询

5. 表数据比较多的时候是否添加了合适的索引

   表的主键、外键必须有索引

   经常出现在where子句中的字段，特别是大表的字段，应该建立索引

   经常用于排序、分组的字段，应当建立索引

   加上索引之后，还应该使用Explain来确认索引是否生效

6. 如果上面的几项都没有问题，那可能就是因为服务器性能或者数据量过大导致的查询慢，此时可以考虑读写分离

   也就是我们搭建一个MySQL的主从集群，让1个主节点负责写入数据，多个从节点负责查询数据，以分摊查询压力

## 查询语句执行流程

![image-20210902082718756](assets/image-20210902082718756.png) 

一条查询语句到达MySQL数据库之后，数据库中的各个组件会按照顺序执行自己的任务

1. 首先是连接器，他会负责建立连接、检查权限等操作
2. 连接成功之后，会查询缓存，如果缓存中有结果会直接返回；如果缓存中没有结果，会将sql交给分析器处理
3. 分析器负责检查sql的词法、语法，如果没有问题，再将sql交给优化器处理
4. 优化器会决定用哪个索引，决定表的连接顺序等，然后将优化之后的sql交给执行器
5. 执行器根据存储引擎类型，调用存储引擎接口
6. 存储引擎负责最后数据的读写

# Redis(*)

## Redis的数据类型有哪些（重点）

Redis是一个键值对的内存型数据库，它的键都是字符串类型

值支持的数据类型有5种，分别是String、List、Hash、Set、ZSet

- String是字符串类型，一般用于缓存一些简单的字符串、数值等内容
- List底层是链表，特点是增删容易，随机访问困难，可以用于消息队列等场景
- Hash类似于Java中的HashMap，适合存储对象
- Set是一种无序集合，在项目中可以用来存储共同粉丝、共同喜好等功能
- ZSet是一种有序的集合，元素会按照score进行排序，适用于存储各种排行榜、热点话题等内容

在这五种类型的基础上，还衍生出了三种常见的类型

- Geo类型：此种数据类型用于保存地理位置，可以用来实现位置共享、附近的人等功能

- Bitmap类型：此类型是一个二进制字符串，其中每个位都可以被设置或清除，可以用来做签到、布隆过滤器等
- HyperLogLog类型：这是一种用来做基础统计的类型，其可以非常省内存的去统计各种计数，比如注册ip、在线用户等准确性不是高的数

>https://www.jb51.net/database/317084scx.htm

## Redis为什么这么快（重点）

Redis之所以运行速度比较快，主要是由于这样一些原因:

1. 纯内存：Redis的绝大部分请求是纯粹的内存操作，非常快速

2. 单线程：Redis的核心部分是单线程运行的，避免了不必要的上下文切换，也不存在线程切换导致的CPU消耗

3. 使用I/O多路复用模型和非阻塞IO

   `I/O多路复用是指利用单个线程来同时监听多个Socket，并在某个Socket可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源`

## Redis的过期删除策略

Redis的过期删除策略指的是当Redis中的key过期之后在什么时候进行删除的处理方案，常用的删除策略就两个：

- 惰性删除：key过期后不会立刻删除，而是在每次访问key的时候判断当前key是否已经到期，如果到期就删除
- 定期删除：通过一个定时任务，周期性的抽样部分过期的key，然后执行删除

两者相比，定期删除对内存更加友好，惰性删除对CPU更加友好。两者各有千秋，所以Redis采用的是定期删除+惰性删除

## Redis如何判断key过期

Redis本质是一个键值型数据库，而这种键值映射底层正式基于哈希表来实现的，在Redis中叫做Dict

在Redis中会有两个Dict，其中一个记录`键--值`，另一个记录`键--过期时间`

要判断一个key是否过期，只需要到记录过期时间的Dict中根据key查询即可

## Redis的内存淘汰策略

Redis的内存淘汰策略指的是当Redis的内存已经存满，又有新的数据需要保存时的处理方案，官方提供了8种淘汰策略：

- no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错
- volatile-ttl：从已设置过期时间的数据中挑选剩余存活时间较短的进行淘汰
- allkeys-random：从所有数据中任意选择数据进行淘汰
- volatile-random：从已设置过期时间的数据中任意选择进行淘汰
- allkeys-lru：从所有数据中选择最近最久未使用的进行淘汰
- volatile-lru：从已设置过期时间的数据中挑选最近最久未使用的进行淘汰
- allkeys-lfu：在所有的数据集中选择最少使用的进行淘汰
- volatile-lfu：从已设置过期时间的数据集挑选最少使用的进行淘汰

## Redis的持久化方式（重点）

Redis是一个基于内存的数据存储，为了保证数据安全，需要将内存中的数据备份到磁盘上，官方提供了两种数据持久化的方式，分别是RDB和AOF

1. RDB采用的是定期更新的方式，它会定期将Redis中的数据生成的快照同步到磁盘上，磁盘上保存的就是Redis的内存快照

   它的优点是数据文件相对较小，数据恢复速度较快；缺点是比较耗内存，存在丢失数据的风险

2. AOF是将Redis所执行过的所有写指令都记录到磁盘上，在下次Redis重启时，只需要将指令重写一遍就可以了

   它的优点是数据丢失的风险大大降低了，缺点是数据文件较大，而且数据恢复的时候速度较慢


在我们公司是同时开启RDB和AOF持久化机制的，这样做的好处是：

1. 在Redis重启时先使用AOF日志进行恢复，然后再使用RDB快照进行备份
2. 而且将AOF的`appendfsync` 参数为 `everysec`，保证每秒将AOF缓冲区中的写操作同步到AOF文件中，提高数据的持久化能力
3. 定期进行RDB快照的备份，以便在需要时进行全量数据的恢复

这样的配置可以充分利用RDB和AOF两种持久化机制的优势，提高数据的可靠性和恢复能力

## RDB时可以写数据吗

Redis在进行RDB期间是可以同时处理写请求的，这得益于Redis使用操作系统的多进程写时复制技术来实现快照持久化

具体来说，就是Redis在持久化时会产生一个子进程，快照持久化完全交给子进程来处理，父进程继续处理客户端请求

当主线程执行写指令修改数据的时候，这个数据就会复制一份副本，子进程读取这个副本数据写到RDB文件

这既保证了快照的完整性，也允许主线程同时对数据进行修改，避免了对正常业务的影响

## Redis集群有哪些方案（重点）

在Redis中提供的集群主要有两种，分别是主从和分片集群

1. 主从集群主要用来解决Redis的读并发问题，一般是一个主节点负责数据写入，多个从节点负责数据读取，主节点的数据会实时同步给从节点

   为了保证主节点的高可用性，Redis还提供了哨兵来监控集群中节点的状态，并在主节点出现问题时进行重新选主，当然哨兵也支持集群部署

2. 分片集群主要用来解决Redis的海量数据存储和并发写问题，它要求有多个主节点，每一要写入的数据会经过计算落到其中一个主节点上

   在这个计算的过程中Redis引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过先经过运算得到一个数值， 然后对16384取余来决定放置哪个槽

   而分片集群的每个节点负责一部分hash槽，这样就可以计算出一个key会出现在哪个节点上了，查询的时候也是同时的方式来定位即可

## 什么是缓存预热

缓存预热是指系统上线后，提前将相关的缓存数据加载到缓存系统，而无需等到访问的时候再进行缓存加载

如果不进行预热，那么Redis初始状态数据为空，系统上线初期，对于高并发的流量，都会访问到数据库中，对数据库造成流量的压力

缓存预热解决方案主要有下面几个：

- 数据量不大的时候，工程启动的时候进行加载缓存动作
- 数据量大的时候，设置一个定时任务脚本，进行缓存的刷新
- 数据量太大的时候，优先保证热点数据进行提前加载到缓存

## 如何保证缓存一致性（重点）

保证Redis和MySQL数据一致性的方案有很多，最常见的有三种：同步双写、异步通知、canal监听

1. 同步双写就是在程序更新完MySQL之后立即同步更新Redis
2. 异步通知就是程序在更新完MySQL后，发送一条消息到MQ中，然后在通过一个程序监听MQ，获取到消息，然后更新Redis
3. Canal监听就是通过Canal监听MySQL的binlog日志变化，然后再通过程序将变化的数据更新数据到Redis中

## 什么是缓存穿透

缓存穿透指的是请求一直在查询一个数据库中不存在的数据，这样缓存中没有，请求就会到达数据库，而数据库也没有，也就没法缓存

所以每一次请求都会直接到数据库中查询，这就极有可能导致数据库被压垮

常用的解决方案有两个：

1. 缓存空值：当我们发现请求的数据在数据库和Redis中都不存在时，就将空值缓存到Redis，避免频繁查询数据库

   这种方式实现简单，但是有可能引发额外的内存消耗，所以我们在缓存空值的时候，要为其设置一个较短的过期时间

2. 使用布隆过滤器：它会拦截掉所有一定不存在于Redis中的数据，从而避免了对数据库的查询

   这种方式优点是占用内存比较少，缺点是实现复杂，有可能产生误判

## 什么是缓存雪崩

缓存雪崩是指在同一时段大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，带来巨大压力

常见的解决方案是：

1. 给不同的key的过期时间添加随机值，这样key的过期时间不同，不会大量key同时过期
2. 利用Redis集群提高服务的可用性，避免缓存服务宕机；并且给缓存业务添加降级限流策略

## 什么是缓存击穿

缓存击穿指的是对于一些设置了过期时间的key，在其缓存失效的瞬间，有大量的请求同时访问它，这些请求在缓存找不到就会直接到数据，导致数据库被压垮

常用的解决方案有两个：

1. 互斥锁：当缓存失效时，不立即去数据库查询，而是先去获取一把全局锁，那个线程获取到了，就去数据库查询，获取不到的就等待重试查询缓存

   这种方式可以保证数据一致性，但是同时会导致性能变差

2. 逻辑过期：

   在设置key的时候，不给它设置过期时间，而是单独设置一个过期时间字段一块存入缓存中

   当查询的时候，从redis取出数据后判断时间是否过期，如果过期则开通另外一个线程进行数据同步，当前线程正常返回数据

   这种方式性能较好，但是无法保证数据一致性，有一段时间会使用旧数据

## 什么是布隆过滤器

布隆过滤是一种数据统计的算法，用于检索一个元素是否存在一个集合中

1. 首先需要一个很长的二级制数，默认每一位都是0
2. 然后需要N个不同算法的哈希函数对指定的一个元素进行运算，得到N个数字
3. 在二级制数中，将得到的N个数对应的bit位标记为1
4. 要判断某个元素是否存在，只需要把元素按照上述方式运算，判断对应的bit位是否是1即可

它的优点是占用空间小，工作效率高，缺点是：它判断不存在的一定不存在，它判断存在的不一定存在，也就是说存在一定程度的误判

## Redis支持事务吗

Redis中本身是没有事务的概念的，但是它有几个命令组合起来能实现类似于事务的效果。也就是说，Redis事务的本质是一组命令的集合。

这里用到的命令主要有5个，分别是：

1. multi：用来组装一个事务
2. exec：执行一个事物
3. discard：取消一个事务
4. watch：用来监视一些key，一旦这些key在事务执行之前被改变，则取消事务的执行
5. unwath：取消 WATCH 命令对所有key的监视

总结说：Redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令

![image-20220225132328333](assets/image-20220225132328333.png) 

# 并发编程

## 进程和线程

一般我们把正在运行的程序就是一个独立的进程；而线程是属于进程的，一个进程中可以同时运行很多个线程

做个类比的话，进程就好像是一列火车，而线程则是火车上的一节车厢

## 并发和并行

进程中的线程是由CPU负责调度执行的，但CPU能同时处理线程的数量有限，为了保证全部线程都能往前执行，

CPU会轮询为系统的每个线程服务，由于CPU切换的速度很快，给我们的感觉这些线程在同时执行，这就是并发（假同时）

在多核CPU的系统中，同一个时刻会有多个线程在被CPU调度执行，这就是并行（真同时）

## 线程的创建方式(*)（重点）

我知道的创建线程的方式大体上可以分为四种：

1. 继承Thread类并重写run方法创建线程，这种方式实现简单但线程类不可以再继承其他类
2. 实现Runnable接口并重写run方法，这种方式避免了单继承局限性，编程更加灵活，实现解耦
3. 实现Callable接口并重写call方法，这种方式可以获取线程执行结果的返回值，并且可以抛出异常
4. 使用线程池创建

## runnable和callable的区别

这两个接口都是线程任务类的接口，区别点在于

- Runnable接口run方法无返回值；Callable接口call方法有返回值，也就是说如果需要获取线程类的执行结果，必须要使用Callable，如果不需要返回结果，则使用Runnable更简单一些
- Runnable接口run方法只能抛出运行时异常，且无法捕获处理；Callable接口call方法允许抛出异常，可以获取异常信息

## start和run方法的区别(*)

run(): 封装了要被线程执行的代码，本质上就是一个普通方法，可以被调用多次

start(): 用来启动线程，底层会自动去执行run方法中的代码，start方法只能被调用一次

也就是启动线程的时候，只能调用start方法，如果调用run方法，不会启动新线程，而是当普通方法调用执行

## 如何保证线程顺序执行(*)

>现在有T1,T2,T3三个线程，如何保证它们按顺序执行？

在多线程中有多种方法让线程按特定顺序执行，最简单的方式就是使用线程类的join方法实现

join方法是Thread类中的一个方法，它的作用是将当前线程挂起，等待其他线程结束后再执行当前线程

具体来说就是：可以在t2之前调用t1.join()，在t3之前调用t2.join()

>现在有T1,T2,T3三个线程，如何保证T3会在T1和T2之后执行

这个需求我们可以使用CountDownLatch来完成

CountDownLatch本质上就相当于一个计数器，我们可以在创建它的时候，可以给出一个初始值2

当T1和T2完成自己的代码时，需要调用CountDownLatch的countDown()方法，他会将计数器减一

而T3代码执行前，需要调用CountDownLatch的await()方法，就是等待，只有计数器的值到0之后，这个方法才会继续执行

![image-20241207172644172](assets/image-20241207172644172.png) 

## 说一下线程的状态及转换

在我的理解中，线程共分为7种状态，分别是：新建、就绪、运行、终止以及阻塞、等待、计时等待

它们之间的转换关系是这样的：

1. 当线程new出来之后，没有start之前就会处于新建状态
2. 当线程执行start方法之后，就进入就绪状态
3. 当就绪的线程一旦获取到了cpu的执行权，就可以进入运行状态
4. 当线程执行完了run方法之后，就进入了死亡状态

这是一条正常的流程，但是代码在运行状态下可以因为一些原因进入到其它状态，比如说：

1. 当进行抢锁操作时，抢锁失败就会进入到阻塞状态
2. 当代码调用了wait方法时，就会进入等待状态
3. 当代码调用了sleep方法时，就会进入计时等待状态

![image-20231117192406734](assets/image-20231117192406734.png) 

## notify和notifyAll的区别

这两个方法都是用户唤醒被wait方法休眠的线程的，区别点在于：notifyAll() 会唤醒所有的线程，notify() 只会唤醒一个线程

notifyAll() 调用后，会将全部线程由等待池移到锁池，然后参与锁的竞争，竞争成功则继续执行， 如果不成功则留在锁池等待锁被释放后再次参与竞争。

notify()只会唤醒一个线程，具体唤醒哪 一个线程由虚拟机控制

## sleep和wait的区别

sleep和wait都是Java中用来让线程暂时放弃CPU使用权，进入阻塞状态的方法。他们的主要区别点有下面几个：

1. 方法归属不同：sleep是Thread的静态方法，而wait是Object的成员方法
2. 醒来时机不同：sleep会在指定的时间后自动苏醒，而wait需要其他线程的唤醒
3. 锁特性不同：sleep不会释放锁，而wait会释放锁
4. 使用限制不同：wait必须用在synchronized代码块中，而sleep无此限制

## 谈谈JMM(*)

JMM(Java Memory Model)指的是Java内存模型，它描述了程序存储和读取内存中变量的规则，大体如下：

1. 所有的共享变量都存储于主内存
2. 每一个线程还存在自己的工作内存，里面保留了被线程使用变量的副本
3. 线程对变量的所有的操作都必须在工作内存中完成，而不能直接读写主内存中的变量
4. 不同线程之间也不能直接访问对方工作内存中的变量，线程间变量的值的传递需要通过主内存完成

![image-20220901123201248](assets/image-20220901123201248-1686791707791.png) 

## Java中有哪些锁

Java中的锁有很多，根据不同的维度，我给您说一下我了解的一些：

1. 悲观锁和乐观锁

   悲观锁：就是认为自己在操作一个共享数据的时候，一定还有其它人来操作，所以直接锁定资源，比如：synchronized、Lock

   乐观锁：就是认为自己在操作一个共享数据的时候，一定不会有其它人来操作，所有不锁定资源，而是在更新前使用类似于CAS的机制去判断

2. 可重入锁和非可重入锁

   可重入锁是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁，不会因为之前已经获取过还没释放而阻塞

   ReentrantLock 和 synchronized 都是可重入锁

   不可重入锁：与可重入相反，获取锁后不能重复获取，否则会死锁（自己锁自己）

3. 自旋锁

   自旋锁即是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待（不放弃 CPU 资源）

   然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环，此时获取锁的线程一直处于活跃状态（而非阻塞）

## synchronized的实现原理

在Java中，每个对象都隐式包含一个 monitor（监视器）对象，加锁的过程其实就是竞争monitor的过程，

当线程进入字节码monitorEnter指令之后，线程将持有monitor对象，执行monitorExit时释放monitor对象

在这个过程中，其它线程就会阻塞等待获取该monitor对象

## synchronized和lock的区别(*)

synchronized和lock都是Java中的悲观锁的实现方式，主要区别如下：

* synchronized是关键字，Lock是是一个接口
* 使用synchronized时，退出同步代码块锁会自动释放，而使用Lock时，需要手动调用unlock方法释放锁, finally
* Lock提供了许多synchronized不具备的功能，例如获取等待状态、公平锁、可打断、可超时、多条件变量
* 在竞争激烈时，Lock的实现通常会提供更好的性能

## 什么是CAS(*)（重点）

CAS就是比较再交换，是乐观锁底层的实现思路，它有3个操作数：**内存值V**，**旧的预期值A**，**要修改的新值B**

也就是说当一个线程试图修改一个内存中的数据时，

1. 它会先读取到内存的这个值，将其保存为旧值

2. 然后再对这个值进行修改，得到一个新值

3. 最后将新值向内存中保存时，会先比对旧值跟内存中当前的值是否一致

   如果一致，代表在当前线程修改期间，并没有其它线程修改内存中的值，此时就可以将新值更新到内存中了

   但是如果不一致，则代表在当前线程修改期间，有其它线程修改内存中的值，那么当前线程就得放弃本次更新，进行重试

## 死锁产生的条件(*)

如果一个进程集合中的每个进程都在等待只能由此集合中的其他进程才能引发的事件，而无限期陷入僵持的局面称为死锁

- 互斥：一个资源每次只能被一个进程使用(资源独立)
- 请求与保持：一个进程因请而阻塞时，对已获得的资源保持不放(不释放锁)
- 不剥夺：进程已获得的资源，在未使用之前，不能强行剥夺(抢夺资源)
- 循环等待：若干进程之间形成一种头尾相接的循环等待的资源关闭(死循环)

![image-20241207180310643](assets/image-20241207180310643.png) 

## volatile关键字的作用

volatile关键字用于修饰变量，它有两大作用：

保证变量在多线程间的可见性：当一个线程修改了volatile修改的变量，其他线程能够立即感知到这个修改

禁止指令重排序：对volatile变量的读写操作，不能被JVM以及CPU指令重排序优化，从而保证操作的顺序性

## 谈一下ConcurrentHashMap(*)

ConcurrentHashMap是一种线程安全的高效Map集合，相比于HashMap来讲，它的效率略低，但是它是线程安全的

在JDK1.7和1.8中它底层采用的数据结构并不一样，下面我分别来给您介绍一下

首先是JDK1.7中，它采用了`分段的数组+链表实现的`

- 首先它提供了一个默认16位的segment数组，这个数组一旦初始化之后便不可扩容
- 在每个segment位置上都可以挂一个HashEntry数组，数组里面可以存储具体的元素，这个HashEntry数组是可以扩容的
- 在HashEntry存储的数组中存储的元素，如果发生冲突，则可以挂单向链表
- 当保存元素时，它会对key计算hash值，先确定segment数组下标，再向hashEntry数组中的下标存储数据
- 为了线程安全，它会使用ReentrantLock保证同一时间只有一个线程可以访问同一个segment

<img src="assets/image-20241207174002811.png" alt="image-20241207174002811" style="zoom:53%;" /> 

在JDK1.8中，放弃了Segment臃肿的设计，开始采用数组+链表/红黑二叉树来实现，这就跟HashMap很像了

区别于HashMap的是，它会采用Synchronized锁定数组首节点的方式来保证只有一个线程可以访问到一个数组中的元素

<img src="assets/image-20230505093507265.png" style="zoom:67%;" /> 



## 线程池的执行流程(*)（重点）

当我们提交一个任务到线程池中，线程池的处理流程如下：

1. 首先判断线程池里的核心线程是否都在执行任务，如果不是，则创建一个新的工作线程来执行任务。
2. 如果核心线程都在执行任务，则判断工作队列是否已满，如果没满，则将新提交的任务存储在这个工作队列里。
3. 如果工作队列满了，则判断线程数是否小于最大线程数，如果是，则创建临时线程直接执行任务
4. 如果线程数已经到达了最大线程数，则会执行对应的拒绝策略逻辑

<img src="assets/线程池的执行原理.jpg" style="zoom:67%;" /> 

## 线程池的核心参数(*)（重点）

线程池在创建的时候最大支持传入7个参数，分别是：

1. 核心线程数

2. 最大线程数

3. 临时线程的空闲时间：临时线程会在空闲这段时间后
4. 临时线程的空闲时间单位

5. 工作队列：用来保存等待执行的任务的

6. threadFactory：设置创建线程的工厂

7. handler：线程池的拒绝策略

## 线程池的拒绝策略有哪些(*)（重点）

拒绝策略是指将任务添加到线程池中时，线程池拒绝该任务所采取的相应策略，官方提供的有4种：

- AbortPolicy：直接抛出异常，默认策略

- CallerRunsPolicy：用调用者所在的线程来执行任务

- DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务
- DiscardPolicy：直接丢弃任务

## 线程池的阻塞队列有哪些(*)（重点）

阻塞队列指的是当线程中核心线程数已满，新任务到达时，存储线程的队列，常见的有下面几种：

- ArrayBlockingQueue：基于数组结构的有界阻塞队列

- LinkedBlockingQueue：基于链表结构的有界阻塞队列
- PriorityBlockingQueue：具有优先级别的阻塞队列
- SynchronousQueue：不存储元素的阻塞队列，每个插入操作都必须等待一个移出操作

## 了解Executors创建线程池吗(*)

了解过，Excutors是JDK提供的一个可以创建线程池的工具类，它可以创建4种线程池

但是用它创建的线程池有的没有限制最大线程数，有的没有限制阻塞队列的长度，这样的话，极大可能导致OOM

因此我们公司不允许我们使用它，而是使用自己传递参数的方式创建线程池

## 如何确定线程池的核心线程数(*)

线程池的核心线程数跟任务的性质有很大关系

1. 对于CPU密集型时，任务可以少配置线程数，推荐配置为CPU核数+1，这样可以使得每个线程都在执行任务 
2. IO密集型时，即该任务需要大量的IO，大部分线程都阻塞，则需要多配置线程数，推荐配置为CPU核数的2倍

# JVM

## 主要组成部分(*)（重点）

<img src="assets/image-20220903233627146.png" alt="image-20220903233627146" style="zoom:80%;" /> 

JVM主要分为下面几部分

- 类加载器：负责将字节码文件加载到内存中

- 运行时数据区：用于保存java程序运行过程中需要用到的数据和相关信息

- 执行引擎：字节码文件并不能直接交给底层操作系统去执行，因此需要特定的命令解析器执行引擎将字节码翻译成底层系统指令

- 本地库接口：会被执行引擎调用参与字节码的翻译

在这里面最主要的部分是运行时数据区，它又由五部分构成，分别是：堆、方法区、栈、本地方法栈、程序计数器

- 堆是对象实例存储的主要区域
- 方法区可以认为是堆的一部分，用于存储已被虚拟机加载的信息，比如常量、静态变量等等
- 栈是程序方法运行的主要区域，栈里面存的是栈帧，栈帧里面存的是局部变量表、操作数栈、动态链接、方法出口等信息
- 本地方法栈与栈功能相同，区别在于本地方法栈执行的是本地方法，即一个Java调用非Java代码的接口
- 程序计数器主要存放的是当前线程所执行的字节码的行号，用于记录正在执行的字节码指令的地址

## 堆栈的区别是什么(*)

堆和栈都是JVM的主要组成部分，不同点在于：

- 栈内存一般会用来存储局部变量和方法调用，但堆内存是用来存储Java对象和数组的
- 堆会GC垃圾回收，而栈不会
- 栈内存是线程私有的，而堆内存是线程共有的
- 两者异常错误不同，栈空间不足：java.lang.StackOverFlowError，堆空间不足：java.lang.OutOfMemoryError

## 类加载器有哪些

类加载器的主要作用就是将字节码文件加载到JVM中，从而让Java程序能够启动起来。根据各自加载范围的不同，主要划分为四种类加载器：

- 启动类加载器(BootStrap ClassLoader)：用于加载JAVA_HOME/jre/lib目录下的类库

- 扩展类加载器(ExtClassLoader)：用于加载JAVA_HOME/jre/lib/ext目录中的类库

- 应用类加载器(AppClassLoader)：用于加载classPath下的类，也就是加载开发者自己编写的Java类

- 自定义类加载器：开发者自定义类继承ClassLoader，实现自定义类加载规则


## 双亲委派模型

双亲委派模型是Java中的一种类加载机制

在双亲委派模型中，类加载器之间形成了一种层次继承关系，从顶端开始依次是：启动类加载器->扩展类加载器->应用类加载器->自定义类加载器

当一个类加载器需要加载某个类时，它首先会委派给其上层类加载器去尝试加载该类。如果父类加载器无法加载该类，子类加载器才会尝试加载

这种层次关系形成了一个从上到下的委派链。



双亲委派模型的主要目的是保证Java类的安全性和避免类的重复加载。当一个类加载器收到加载请求时，它会首先检查自己是否已经加载了该类

如果已经加载，则直接返回该类的Class对象；如果未加载，则将加载请求委派给父类加载器

父类加载器也会按照同样的方式进行检查，直到顶层的启动类加载器。如果顶层的启动类加载器无法加载该类，那么子类加载器会尝试自己加载

这样可以避免同一个类被不同的类加载器加载多次，确保类的唯一性



双亲委派模型的优势在于能够保证类的一致性和安全性

通过委派链的机制，可以避免恶意代码通过自定义的类加载器加载替换系统核心类，从而提高了Java程序的安全性

此外，通过双亲委派模型，可以实现类的共享和重用，减少内存占用和加载时间，提高了系统的性能

## 类加载器的执行过程

类从被加载到虚拟机内存中开始，直到卸载出内存为止，整个生命周期包括了7个阶段：加载、验证、准备、解析、初始化、使用、卸载

1. 加载: 这个阶段会在内存中生成一个代表这个类的java.lang.Class对象
2. 验证: 这个阶段的主要目的是为了确保Class文件包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全
3. 准备: 这个阶段正式为类变量分配内存并设置类变量的初始值，注意这里的初始值指的是默认值，而不是代码=后的实际值
4. 解析: 这个阶段将符号引用替换为直接引用，比如方法中调用了其他方法，方法名可以理解为符号引用，而直接引用就是使用指针直接引用方法
5. 初始化: 这个阶段是执行类构造器方法的过程，是类加载的最后一步，到了这一步Java虚拟机才开始真正执行类中定义的Java程序代码(字节码)
6. 使用: 这个节点程序在运行		   
7. 卸载: 这个阶段类Class对象被GC

<img src="assets/image-20220904003730785.png" style="zoom:80%;" /> 

## 怎么判断对象是否可回收

在堆中存放着几乎所有的对象实例，垃圾收集器在对堆进行回收前，第一件事就是要确定哪些对象是要回收的

JVM认为不被引用的对象就是可以被回收的对象，而它确认对象是否还在被引用的算法主要有两种：引用计数法和可达性分析算法

1. 引用计数法

   在对象头处维护一个counter，每增加一次对该对象的引用，计数器自加，如果对该对象的引用失联，则计数器自减

   当counter为0时，表明该对象已经被废弃，不处于存活状态,

   但是此方法存在问题，假设两个对象相互引用始终无法释放counter，则永远不能GC

2. 可达性分析算法

   通过一系列为GC Roots的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链

   当一个对象到GC Roots没有任何引用链相连时，则证明该对象是不可用的

   可以作为GC Roots的对象一般有栈中引用的对象 、方法区中类静态属性引用的对象以及

## 垃圾回收算法有哪些(*)

目前JVM中的垃圾回收算法主要有四个，分别是：标记清除算法、标记-整理算法、复制算法和分代收集算法

1. 标记清除算法是将垃圾回收分为2个阶段，分别是标记和清除

   它会先使用根据可达性分析算法找到垃圾资源进行标记，然后对这些标记为可回收的内容进行垃圾回收

   这种算法的主要不足有两个：

   - 效率问题，标记和清除阶段都要遍历多有对象，并且在GC时，需要停止应用程序，对于交互性要求比较高的应用而言这个体验是非常差的

   - 空间问题，对象被回收之后会产生大量不连续的内存碎片，当需要分配较大对象时，由于找不到合适的空闲内存而不得不再次触发垃圾回收动作

2. 标记整理算法也是将垃圾回收分为2个阶段，分别是标记和整理清除

   它的第一阶段也是会先将存活的对象先标记出来

   不一样的地方在于第二阶段，它会将所有存活的对象向前移动放在一起，然后将无用空间回收，这样就会出现连续的可用空间了

   所以它解决了空间碎片问题，但是效率低的问题依旧存在

3. 复制算法，将原有的内存空间一分为二，每次只用其中的一半

   在垃圾回收时，将正在使用的对象复制到另一个内存空间中，然后将当前内存空间清空，交换两个内存的角色，完成垃圾的回收。

   这种算法的缺点在于分配2块内存空间，在同一个时刻，只能使用一半，内存使用率较低

4. 分代收集算法，它会将整个堆内存分成几部分空间，每个空间中放入不同类型的对象，然后各自适合的算法回收

   在JDK8时，堆被分为了两份：新生代和老年代，默认空间比例为1:2

   对于新生代，内部又被分为了三个区域：Eden区，S0区，S1区，，默认空间比例为8：1：1

   ![image-20200825231704058](assets/image-20200825231704058.png) 

   **它的基本工作机制是：**

   当创建一个对象的时候，这个对象会被分配在新生代的Eden区，当Eden区要满了时候，触发MinorGC

   当进行MinorGC后，此时在Eden区存活的对象被移动到S0区，并且当前对象的年龄会加1，清空Eden区

   当再一次触发MinorGC的时候，会把Eden区中存活下来的对象和S0中的对象，移动到S1区中，这些对象的年龄会加1，清空Eden区和S0区

   当再一次触发YoungGC的时候，会把Eden区中存活下来的对象和S1中的对象，移动到S0区中，这些对象的年龄会加1，清空Eden区和S1区

   对象的年龄达到了某一个限定的值（默认15岁），那么这个对象就会进入到老年代中，除此之外，大对象也会直接放入老年代空间

   当老年代满了之后，触发FullGC**。**FullGC同时回收新生代和老年代

   在上述过程中，新生代中的对象存活率比较低，所以选用复制算法；老年代中对象存活率高，所以使用标记-整理算法

**小细节：**

1. 当对新生代产生GC：MinorGC，老年代代产生GC：Major GC ，新生代和老年代产生FullGC

2. Minor GC非常频繁，一般回收速度也很快，Major GC一般会伴随一次Minor GC，Major GC的速度要慢很多，一般要比Minor GC慢10倍

3. 占用内存较大的对象，对于虚拟机内存分配是一个坏消息，虚拟机提供了一个-XX:PretenureSizeThreshold让大于这个设置的对象直接存入老年代

4. 虚拟机给每个对象定义了一个Age年龄计数器，对象在Eden中出生并经过第一次Minor GC后仍然存活，年龄+1，此后每熬过一次Minor GC则年龄+1，

   当年龄增加到一定程度(默认15岁)，就会晋升到老年代。可通过参数设置晋升年龄 -XX:MaxTenuringThreshold 

## 垃圾回收器都有哪些(*)

JVM中常见的一些垃圾回收器有：

- 新生代回收器：Serial、ParNew、Parallel Scavenge

- 老年代回收器：Serial Old、Parallel Old、CMS

- 整堆回收器：G1

新生代垃圾回收器一般采用的是复制算法，复制算法的优点是效率高，缺点是内存利用率低

老年代回收器一般采用的是标记-整理的算法进行垃圾回收

# 其他

## 说几个常见的Linux命令

1. 日常运维
	查端口 netstat -ano | grep 8080
	查进程 ps -ef | grep tomcat
	强杀进程 kill -9 进程号
	查看ip ifconfig 
	测试网络  ping 主机ip
	内存使用情况 free -g

2. 查看文件内容
	看文件中出现了java:  more 文件 | grep java
	动态查看日志内容:    tail -f 文件

3. 权限
	赋权  chmod 7(主人 读 写 执行) 7(同组人) 7(其它人) -R 目录(文件)
	
4. 文件大小
	目录大小 du -h 
	磁盘大小 df -h

## 说几个常见的docker命令

1. 镜像
	查看 docker images
	拉取 docker pull
	删除 docker rmi
	打包 docker save -o tomcat.tar tomcat:8.0
	导入 docker load -i tomcat.tar
2. 容器
	基础操作 docker ps|start|stop|restart 容器名
	运行 docker run -p 端口映射 --name 名字  -v 数据卷 -d 镜像
	进入 docker exec -it /bin/bash 容器名
	日志 docker logs -f 容器名

## 说几个常见的Vue指令

![img](assets/download_image-1733903504445.webp) 

## Vue的生命周期

Vue 实例有⼀个完整的⽣命周期，也就是从开始创建、初始化数据、编译模版、挂载Dom -> 渲染、更新 -> 渲染、卸载 等⼀系列过程，称这是Vue的⽣命周期。 

1. **beforeCreate（创建前）**：数据观测和初始化事件还未开始，此时 data 的响应式追踪、event/watcher 都还没有被设置，也就是说不能访问到data、computed、watch、methods上的方法和数据。
2. **created（创建后）**：实例创建完成，实例上配置的 options 包括 data、computed、watch、methods 等都配置完成，但是此时渲染得节点还未挂载到 DOM，所以不能访问到 $el 属性。
3. **beforeMount（挂载前）**：在挂载开始之前被调用，相关的render函数首次被调用。实例已完成以下的配置：编译模板，把data里面的数据和模板生成html。此时还没有挂载html到页面上。
4. **mounted（挂载后）**：在el被新创建的 vm.$el 替换，并挂载到实例上去之后调用。实例已完成以下的配置：用上面编译好的html内容替换el属性指向的DOM对象。完成模板中的html渲染到html 页面中。此过程中进行ajax交互。
5. **beforeUpdate（更新前）**：响应式数据更新时调用，此时虽然响应式数据更新了，但是对应的真实 DOM 还没有被渲染。
6. **updated（更新后）** ：在由于数据更改导致的虚拟DOM重新渲染和打补丁之后调用。此时 DOM 已经根据响应式数据的变化更新了。调用时，组件 DOM已经更新，所以可以执行依赖于DOM的操作。然而在大多数情况下，应该避免在此期间更改状态，因为这可能会导致更新无限循环。该钩子在服务器端渲染期间不被调用。
7. **beforeDestroy（销毁前）**：实例销毁之前调用。这一步，实例仍然完全可用，this 仍能获取到实例。
8. **destroyed（销毁后）**：实例销毁后调用，调用后，Vue 实例指示的所有东西都会解绑定，所有的事件监听器会被移除，所有的子实例也会被销毁。该钩子在服务端渲染期间不被调用

## Vue组件之间传值

**父传子** : 子组件上添加props 

**子传父** : 子组件通过Vue实例方法$emit进行触发并且可以携带参数，父组件监听使用`@v-on`进行监听 

**非父子 :**  第三方new Vue定义为eventBus，created中订阅方法eventBus.*on*，另一个兄弟组件中的*methods*中写函数，在函数中发布*eventBus*订阅的方法*`eventBus`*`.emit("自定义事件名”) `，在组件的template中绑定事件(比如click)



>https://www.bilibili.com/video/BV14z4y1N7pg?spm_id_from=333.788.videopod.episodes&p=80

## v-if和v-show的区别

**v-if** 是动态添加，当值为 **false** 时，是完全移除该元素，即 **dom** 树中不存在该元素

**v-show** 仅是隐藏 / 显示，值为 **false** 时，该元素依旧存在于 **dom** 树中。若其原有样式设置了 **display: none** 则会导致其无法正常显示

## 账号密码的登录流程

用户使用账号密码登录的本质就是对员工表进行查询操作

1. 首先要接收前端提交的账号和密码

2. 然后根据账号在数据库员工表进行查询，如果没有查到，说明此账号不存在，可以直接给前端返回一个提示

3. 如果查询到了说明这个账号存在，接下来就要进行前端传入密码和数据库查询到的密码比对

   如果比对失败，说明用户提供的密码不对，可以直接给前端返回一个提示

   如果比对没有问题，说明用户提供的账户和密码是正确的，此时登录成功

4. 登录成功之后，后端需要生成一个标识用户身份的token，返回给前端，前端会将token保存起来

   后面前端再发请求的时候，需要携带着这个token，而后端需要编写一个拦截器，用于拦截请求，校验token

   校验通过，则放行请求，正常访问；校验失败，则禁止通行，返回提示

## 前端小程序的微信登录流程

微信登录的核心是通过微信小程序提供的临时凭证code换取永久凭证openid的过程

1. 首先微信小程序会向微信官方申请一个临时登录code

2. 然后小程序带着code向后台服务发送请求，后台接收到code后，会调用微信官方接口验证code是否合法

   如果合法，官方会返回一个openid；这个openid就是此用户在我们系统中的唯一标识，同时也代表用户身份合法

3. 后台服务接收到来着微信的openid之后，会去数据库查询一下是否存在此账户；

   如果存在，代表这是一个老用户，如果不存在，则代表这是一个新用户首次使用我们的系统，我们需要将其信息保存到用户表中

4. 登录成功之后，需要生成一个标识用户身份的token，返回给前端，前端会将token保存起来

   用户后面访问系统的时候，需要携带着这个token，而我们后端需要编写一个拦截器，用于拦截请求，校验token

   校验通过，则放行请求，正常访问；校验失败，则禁止通行，返回提示

## 网关鉴权怎么实现的

1. 用户请求认证服务进行登录，认证成功向前端返回token
2. 前端携带token请求网关，网关通过过滤器（GlobalFilter）拦截请求，获取token
3. 解析token拿到用户信息，如果token合法则继续，否则拒绝访问
4. 网关将用户放在http头中向下传到微服务
5. 微服务通过拦截器获取用户信息并写入Threadlocal中方便在service方法获取当前用户信息
6. 微服务在远程调用时通过Feign的拦截器将当前登录用户信息写入http头中
7. 以上是用户认证在网关校验身份合法性的过程
8. 用户的权限校验我们是在微服务中进行的，微服务通过Spring security进行权限判断，具体是在controller方法上添加`@PreAuthorize`注解，在注解中指定该方法对应的权限字符串，用户拥有此权限则继续访问该方法，否则拒绝访问此方法

## 项目是如何做限流的



## 事务失效的场景有哪些



## 有没有做过服务的链路追踪  skywalking

## 如何设计数据表



## 跨域产生的原因，后端怎么解决



## 请求调用流程



## UUID和数值主键比较



## 有没有遇到过内存溢出 , 如何排查解决

**内存溢出**就是申请的内存超过了可用内存，内存不够了 , 在JVM的几个内存区域中，除了程序计数器外，其他几个运行时区域都有发生内存溢出（OOM）异常的可能，重点是堆和栈

**Java堆溢出 :** Java堆用于储存对象实例，只要不断创建不可被回收的对象，比如静态对象，那么随着对象数量的增加，总容量触及最大堆的容量限制后就会产生内存溢出异常 OutOfMemoryError

1. 误用线程池导致的内存溢出 , 使用了无界队列 , 一直添加任务 或者 线程数设置的比较大 , 创建了大量线程有可能导致堆内存溢出
2. 死循环频繁创建大量的对象 , 或者从数据库查询大量的数据 , 有可能导致堆内存溢出

**虚拟机栈溢出 :** JDK使用的HotSpot虚拟机的栈内存大小是固定的，不断地去创建线程，因为操作系统给每个进程分配的内存是有限的，所以到最后，也会发生OutOfMemoryError异常 , 再比如递归调用没有正常退出, 递归的次数比较多也有可能出现OutOfMemoryError

1. 递归调用的时候 , 没有设置退出条件, 递归次数比较多的时候有可能会出现栈溢出
2. 在大量循环或者死循环的情况下有可能会出现栈溢出

首先当内存溢出问题发生的时候我们首先要定位问题 , 然后解决问题 , 一般内存溢出会出现的现象主要有 : 

1. 用户反馈接口响应时间变长, 程序比较卡
2. CPU跑的过高，使用率持续飙升
3. 内存占用持续升高
4. 服务器运行日志中看到大量的服务调用失败

![img](assets/image-1733900327883.png) 

**解决方案 :** 

启用备用服务器, 将流量切换到备用服务器 , 保证服务正常运行, 然后进行排查 , 甚至直接重启服务器

**可以使用Nacos注册中心中的服务权重管理切换 , 先启动备用服务器, 然后慢慢降低问题服务器权重**

**首先要排除掉一些明显的情况 , 例如 :** 

1. 查看服务器监控信息, 查看网络带宽使用是否异常 , 如果异常可能因为大量请求导致 ,需要分析请求来源是正常用户访问还是异常攻击 , 正常访问代表服务器性能不足, 需要进行调优或者加机器 , 异常攻击需要对应处理(黑名单 , IP限流之类的)
2. 有没有出现下游服务调用异常(监控工具skyworking) , 看哪一个服务接口响应速度比较慢甚至直接超时 
3. 有没有出现慢SQL查询(监控工具或者慢查询日志)
4. 检查之前稳定版本和目前线上版本的代码差异, 有没有出现大量循环 , 大量数据加载, 线程池设置不合理情况
5. 如果实在无法定位可以通过JVM所提供的分析工具进行分析

**JVM分析工具**

1. 通过jmap指定打印JVM的内存快照 dump

jmap只能打印在运行中的程序

有的情况是内存溢出之后程序则会直接中断 , 所以建议通过参数的方式的生成dump文件，

配置如下：`-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/home/app/dumps/` 指定生成后文件的保存目录

1. 使用`JVisualVM`工具去加载并分析dump文件

![img](assets/download_image-1733900331013.png) 

1. 通过查看堆信息的情况，可以大概定位内存溢出是哪行代码出了问题

![img](assets/download_image-1733900334804.png) 

1. 找到对应的代码，通过阅读上下文的情况，进行修复即可

## 线上环境CPU占用100% , 如何排查解决👍

**首先要定位问题 , 是哪一个程序导致的CPU使用率飙升 , 排查方式**

1. 使用top命令查看占用cpu的情况

![img](assets/download_image-1733900338427.png) 

1. 通过top命令查看后，可以查看是哪一个进程占用cpu较高，上图所示的进程为：30978
2. 查看当前进程中的线程信息 `ps H -eo pid,tid,%cpu | grep 30978`

- pid: 进程id
- tid 进程中的线程id
- % cpu使用率 

1. 通过上面分析，在进程(30978)中哪一个线程(30979)占用的cpu较高
2. 把线程号转换为16进制 , 记住这个16进制的线程号

`printf "%x\n" 30979` , 30979为10进制进程id

1. 执行`jstack 30978`可以根据线程 id 找到有问题的线程，进一步定位到问题代码的源码行号

jstack 进程ID

1. 找到问题出现在哪个位置 , 去源代码中找到代码, 进行修复即可

## 有没有遇到过内存泄露问题 , 如何排查解决

内存泄露问题排查 , 同内存溢出, 一般情况下内存泄露会导致内存溢出

3. 